{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAMIDSpiyalong/ECEN-689/blob/main/Lab1_Classification_and_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E32xZbOYPUm"
      },
      "source": [
        "# Section 1: Image Classification of an American Sign Language Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osC2cLOpYPUn"
      },
      "source": [
        "In this section, we will perform the data preparation, model creation, and model training steps using a dataset with images of hands making letters in [American Sign Language](http://www.asl.gs/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiKRPw7gYPUn"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiOK46uZYPUn"
      },
      "source": [
        "1. Use the [Keras API](https://keras.io/) to load the dataset and prepare it for training\n",
        "2. Create a simple neural network to perform image classification\n",
        "3. Create a convolutional neural network (CNN) for the same problem\n",
        "4. Observe the performance of the trained neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Problem: Image Classification"
      ],
      "metadata": {
        "id": "tmr_VYSm-oDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In traditional programming, the programmer is able to articulate rules and conditions in their code that their program can then use to act in the correct way. This approach continues to work exceptionally well for a huge variety of problems.\n",
        "\n",
        "Image classification, which asks a program to correctly classify an image it has never seen before into its correct class, is near impossible to solve with traditional programming techniques. How could a programmer possibly define the rules and conditions to correctly classify a huge variety of images, especially taking into account images that they have never seen?\n",
        "\n",
        "In this lab, the problem is to build a model to automatically classify a given hand guesture in an image to the correct letter category. Humans can do this task fairly easy but it is difficult for traditional codes. Nerual network is more suitable for this kind of complex problem if we have enough traing data."
      ],
      "metadata": {
        "id": "Tos8E4AG-qdF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szIr8wuPYPUn"
      },
      "source": [
        "## American Sign Language Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x17sf8RmYPUo"
      },
      "source": [
        "The [American Sign Language alphabet](http://www.asl.gs/) contains 26 letters. Two of those letters (j and z) require movement, so they are not included in the training dataset. The following code downloads the dataset hosted on the cloud to your colan directory. You can find the files in your file explorer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1I4whR9YZwwTlDnwP4Y9zpMRlKFmwALpN')\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1NwdQljfXfF8CwE4F1X62mmH9x0S9cyYr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "F5R_R8jVokdB",
        "outputId": "c76987d7-11b9-4e05-a12d-aa1dffd4cc23"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1I4whR9YZwwTlDnwP4Y9zpMRlKFmwALpN\n",
            "To: /content/sign_mnist_train.csv\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 148MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1NwdQljfXfF8CwE4F1X62mmH9x0S9cyYr\n",
            "To: /content/sign_mnist_test.csv\n",
            "100%|██████████| 21.8M/21.8M [00:00<00:00, 135MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sign_mnist_test.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh6caR2NYPUo"
      },
      "source": [
        "### Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8rLNUqGYPUo"
      },
      "source": [
        "This dataset is available from the website [Kaggle](http://www.kaggle.com), which is a fantastic place to find datasets and other deep learning resources. In addition to providing resources like datasets and \"kernels\" that are like these notebooks, Kaggle hosts competitions that you can take part in, competing with others in training highly accurate models.\n",
        "\n",
        "If you're looking to practice or see examples of many deep learning projects, Kaggle is a great site to visit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyqZ45KHYPUo"
      },
      "source": [
        "## Training and Validation Data Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BFJhI4CYPUo"
      },
      "source": [
        "When working with images for deep learning, we need both the images themselves, usually denoted as `X`, and also, correct [labels](https://developers.google.com/machine-learning/glossary#label) for these images, usually denoted as `Y`. Furthermore, we need `X` and `Y` values both for *training* the model, and then, a separate set of `X` and `Y` values for *validating* the performance of the model after it has been trained. Therefore, we need 4 segments of data for the dataset:\n",
        "\n",
        "1. `x_train`: Images used for training the neural network\n",
        "2. `y_train`: Correct labels for the `x_train` images, used to evaluate the model's predictions during training\n",
        "3. `x_valid`: Images set aside for validating the performance of the model after it has been trained\n",
        "4. `y_valid`: Correct labels for the `x_valid` images, used to evaluate the model's predictions after it has been trained\n",
        "\n",
        "The process of preparing data for analysis is called [Data Engineering](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). To learn more about the differences between training data and validation data (as well as test data), check out [this article](https://machinelearningmastery.com/difference-test-validation-datasets/) by Jason Brownlee."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data"
      ],
      "metadata": {
        "id": "IeWwNBddDI7K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YotQkJjwYPUp"
      },
      "source": [
        "The sign language dataset is in [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) (Comma Separated Values) format, the same data structure behind Microsoft Excel and Google Sheets. It is a grid of rows and columns with labels at the top, train and test dataset shold be downloaded in your colab folder now.\n",
        "\n",
        "To load and work with the data, we'll be using a library called [Pandas](https://pandas.pydata.org/), which is a highly performant tool for loading and manipulating data. We'll read the CSV files into a format called a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "metadata": {
        "id": "ormmSc9qYPUp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIY20QMjYPUq"
      },
      "source": [
        "Pandas has a [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method that expects a csv file, and returns a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {
        "id": "KFMSfDtQYPUq"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"sign_mnist_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc5lHhbaYPUq"
      },
      "source": [
        "### Exploring the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGVehEEqYPUq"
      },
      "source": [
        "Let's take a look at our data. Each row is an image which has a `label` column, and also, 784 values representing each pixel value in the image. Note that the labels currently are numerical values, not letters of the alphabet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {
        "id": "ASGwU6MAYPUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "baec5afe-41b0-4877-9c40-e99c004f7b9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0          3     107     118     127     134     139     143     146     150   \n",
              "1          6     155     157     156     156     156     157     156     158   \n",
              "2          2     187     188     188     187     187     186     187     188   \n",
              "3          2     211     211     212     212     211     210     211     210   \n",
              "4         13     164     167     170     172     176     179     180     184   \n",
              "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "27450     13     189     189     190     190     192     193     193     193   \n",
              "27451     23     151     154     157     158     160     161     163     164   \n",
              "27452     18     174     174     174     174     174     175     175     174   \n",
              "27453     17     177     181     184     185     187     189     190     191   \n",
              "27454     23     179     180     180     180     182     181     182     183   \n",
              "\n",
              "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0         153  ...       207       207       207       207       206   \n",
              "1         158  ...        69       149       128        87        94   \n",
              "2         187  ...       202       201       200       199       198   \n",
              "3         210  ...       235       234       233       231       230   \n",
              "4         185  ...        92       105       105       108       133   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "27450     193  ...       132       165        99        77        52   \n",
              "27451     166  ...       198       198       198       198       198   \n",
              "27452     173  ...       121       196       209       208       206   \n",
              "27453     191  ...       119        56        27        58       102   \n",
              "27454     182  ...       108       132       170       194       214   \n",
              "\n",
              "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              "0           206       206       204       203       202  \n",
              "1           163       175       103       135       149  \n",
              "2           199       198       195       194       195  \n",
              "3           226       225       222       229       163  \n",
              "4           163       157       163       164       179  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "27450       200       234       200       222       225  \n",
              "27451       196       195       195       195       194  \n",
              "27452       204       203       202       200       200  \n",
              "27453        79        47        64        87        93  \n",
              "27454       203       197       205       209       215  \n",
              "\n",
              "[27455 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-37e50355-bff7-4525-862f-39411be3bbc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27450</th>\n",
              "      <td>13</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>193</td>\n",
              "      <td>193</td>\n",
              "      <td>193</td>\n",
              "      <td>193</td>\n",
              "      <td>...</td>\n",
              "      <td>132</td>\n",
              "      <td>165</td>\n",
              "      <td>99</td>\n",
              "      <td>77</td>\n",
              "      <td>52</td>\n",
              "      <td>200</td>\n",
              "      <td>234</td>\n",
              "      <td>200</td>\n",
              "      <td>222</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27451</th>\n",
              "      <td>23</td>\n",
              "      <td>151</td>\n",
              "      <td>154</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>160</td>\n",
              "      <td>161</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>166</td>\n",
              "      <td>...</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>196</td>\n",
              "      <td>195</td>\n",
              "      <td>195</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27452</th>\n",
              "      <td>18</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>174</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>174</td>\n",
              "      <td>173</td>\n",
              "      <td>...</td>\n",
              "      <td>121</td>\n",
              "      <td>196</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27453</th>\n",
              "      <td>17</td>\n",
              "      <td>177</td>\n",
              "      <td>181</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>119</td>\n",
              "      <td>56</td>\n",
              "      <td>27</td>\n",
              "      <td>58</td>\n",
              "      <td>102</td>\n",
              "      <td>79</td>\n",
              "      <td>47</td>\n",
              "      <td>64</td>\n",
              "      <td>87</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27454</th>\n",
              "      <td>23</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>180</td>\n",
              "      <td>180</td>\n",
              "      <td>182</td>\n",
              "      <td>181</td>\n",
              "      <td>182</td>\n",
              "      <td>183</td>\n",
              "      <td>182</td>\n",
              "      <td>...</td>\n",
              "      <td>108</td>\n",
              "      <td>132</td>\n",
              "      <td>170</td>\n",
              "      <td>194</td>\n",
              "      <td>214</td>\n",
              "      <td>203</td>\n",
              "      <td>197</td>\n",
              "      <td>205</td>\n",
              "      <td>209</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27455 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37e50355-bff7-4525-862f-39411be3bbc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0b9f8b7d-9ddf-4a8c-bbd9-83958707d632\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b9f8b7d-9ddf-4a8c-bbd9-83958707d632')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0b9f8b7d-9ddf-4a8c-bbd9-83958707d632 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37e50355-bff7-4525-862f-39411be3bbc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37e50355-bff7-4525-862f-39411be3bbc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 475
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training dataset containes 27,455 grayscale images of hand gestures, corresponding to the first dimension of the matrix `train_df`. By executing the following cells, we can see the shape of the dataset 27455x785. Each row (image) itself will be reshaped back to the dimensions 28x28 without the labels. Similarly, there are 7,172 validation images."
      ],
      "metadata": {
        "id": "V6yAZRYNGBWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTJKXR3_GGgV",
        "outputId": "4763b91f-1443-489b-95ff-894347a352a1"
      },
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 476
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCS7YtwyGQ8t",
        "outputId": "82520feb-dc6a-45a5-98c0-0e5ce3e529a9"
      },
      "execution_count": 477,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 477
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsY_ba7SYPUq"
      },
      "source": [
        "### Extracting the Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fEnaO1vYPUq"
      },
      "source": [
        "We would like to store our training and validation labels in `y_train` and `y_valid` variables. Notice that the unique number lables are missing number 9 and 25 corresponding to letter `j` and `z`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {
        "id": "_oSIIfHOYPUr"
      },
      "outputs": [],
      "source": [
        "y_train = train_df['label']\n",
        "y_valid = valid_df['label']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(y_train.unique()))\n",
        "print(sorted(y_valid.unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqioVxXp0vau",
        "outputId": "0a851fa4-e24d-4a0c-f27a-e644d4070ace"
      },
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "512aCkAiYPUr"
      },
      "source": [
        "### Extracting the Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXI9rk73YPUr"
      },
      "source": [
        "We would like to store our training and validation images in `x_train` and `x_valid` variables. Here we create those variables. Note that we are dropping the `label` column so the second dimension of the dataset become 784 from 785."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 480,
      "metadata": {
        "id": "pNP2JkiAYPUr"
      },
      "outputs": [],
      "source": [
        "x_train = train_df.drop(['label'],axis=1).values\n",
        "x_valid = valid_df.drop(['label'],axis=1).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cly_1DElYPUs"
      },
      "source": [
        "We now have 27,455 images with 784 pixels each for training..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 481,
      "metadata": {
        "id": "wJFq11_bYPUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbc6939-0038-477a-9282-f56dc3ec3956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 481
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfWp7Q8wYPUs"
      },
      "source": [
        "...as well as their corresponding labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "HHepzMrGYPUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb42dd0c-9f24-4289-805e-4a6ce26dc49d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455,)"
            ]
          },
          "metadata": {},
          "execution_count": 482
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykCJ1iGCYPUs"
      },
      "source": [
        "For validation, we have 7,172 images..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {
        "id": "YxI0nREUYPUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d96e4df-6727-4b2e-cc87-311ea7c775f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 483
        }
      ],
      "source": [
        "x_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_O7539YPUs"
      },
      "source": [
        "...and their corresponding labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {
        "id": "pFqTQF-EYPUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f755082d-2bac-4b07-a27d-a6e83ad76987"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172,)"
            ]
          },
          "metadata": {},
          "execution_count": 484
        }
      ],
      "source": [
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ0dm6ryYPUs"
      },
      "source": [
        "## Visualizing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In neural networks, reshaping alters the dimensions of input tensors, flattening converts multi-dimensional arrays into one-dimensional vectors, and concatenating combines tensors along a specific axis. These operations enable efficient data manipulation, compatibility with different layers, and the integration of information from multiple sources or pathways within the network architecture. The following example shows what happens when we reshape."
      ],
      "metadata": {
        "id": "pUAZ8zn1Iauo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Creating a 1D array with 12 elements\n",
        "original_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "\n",
        "# Reshaping the 1D array to a 2D array with 4 rows and 3 columns\n",
        "reshaped_array = original_array.reshape(4, 3)\n",
        "\n",
        "print(\"Original 1D array:\")\n",
        "print(original_array)\n",
        "print(\"Reshaped 2D array:\")\n",
        "print(reshaped_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4LgCygSIa34",
        "outputId": "7bc12c4a-0ae3-4221-d647-b901b874c284"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original 1D array:\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
            "Reshaped 2D array:\n",
            "[[ 1  2  3]\n",
            " [ 4  5  6]\n",
            " [ 7  8  9]\n",
            " [10 11 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row has the dimension of 784."
      ],
      "metadata": {
        "id": "A0UEjs6VLtTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV29Zo8LMMF2",
        "outputId": "c546c4ca-2efb-4326-e298-aea21c7f6866"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmRb6wtDYPUt"
      },
      "source": [
        "To visualize the images, we will use the matplotlib library. We don't need to worry about the details of this visualization, but if interested, you can learn more about [matplotlib](https://matplotlib.org/) at a later time.\n",
        "\n",
        "Note that we'll have to reshape the first data from its current 1D shape of 784 pixels, to a 2D shape of 28x28 pixels to make sense of the image:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Replace this with your 784-dimensional vector representing the image\n",
        "image_vector = x_train[0]\n",
        "\n",
        "# Reshape the image vector to a 28x28 matrix\n",
        "image_matrix = image_vector.reshape(28, 28)\n",
        "\n",
        "# Visualize the image\n",
        "plt.imshow(image_matrix, cmap='gray')\n",
        "plt.title(\"Reshaped Image\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "X7_RN6ZIIYOk",
        "outputId": "df6263a0-a9da-4c74-c814-cfa82f24a3f6"
      },
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can show 20 images with the labels."
      ],
      "metadata": {
        "id": "R3MEgCTdL03I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {
        "id": "g0j3KPjxYPUt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "49df9b1b-35b0-4ff6-c7d0-bb98602ac1fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 4000x4000 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAADC8AAAFECAYAAAC9efVGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACLrElEQVR4nOzdd7SnVWEv/H2m995ow8AIAwhIVxGkKCoKvNZ4NUaJJbZcU1Bzb5IVk9xijNHkGjVXrxqJieY1xpIIxkITCx2pQxmYwvTe+8x5/7gr8+bQ9hfZv9+ZOfP5rOVanh/fs/f+PWU/e+/neeb09Pb29hYAAAAAAAAAAAAAAIAOGdTfDQAAAAAAAAAAAAAAAAY2Ly8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB01pL8bwP5r586d5YEHHigLFiwoS5YsKZs2bSq7du0q48aNK5MnTy4nn3xyOf7448vgwYP7u6kAzT344IPlrrvuKosXLy5bt24tI0eOLNOnTy/HHntsed7znleGDx/e300EeEZ6e3vLggULyj333FMWL15c1q9fX4YPH14mTpxYjjnmmHLmmWeWESNG9HczAZ4VfR3Ak1u2bFl56KGHyqJFi8rq1avL1q1by7Bhw8r48ePLrFmzyhlnnFEmTZrU380EaG7Lli3l5ptvLg899FBZt25dKaWU8ePHl6OOOqqceOKJ5YgjjujnFgL8Xzt27Ch33nlnmTt3blm3bl3Ztm1bGTduXJk2bVo57bTTynOe85zS09PT380E6Or62/r168s999yzbyy3a9euMnHixDJjxozy/Oc/vxxyyCFN6gFowXN2wMFCf0cLXl6gj2984xvlRz/6UfnpT39aHnjggbJ79+6nzY8fP7686U1vKr/1W79VjjvuuC61EqAzNm3aVP76r/+6fOELXyjz589/ytywYcPKWWedVV7/+teX3/qt3+piCwGemXXr1pVvf/vb5d/+7d/KtddeW1avXv2U2aFDh5ZXvepV5bd/+7fLeeed18VWAjw7+jrgQLZkyZJyyy23lJtvvrnccsst5bbbbiubNm3a99+PPPLIsmDBgmdc7sKFC8s//MM/lBtvvLHcdtttT9s3/ruzzjqr/MZv/EZ529veVoYMsWwMtNWp/u6p3HjjjeWTn/xkufrqq8vOnTufMnfYYYeVl7/85eWKK64oJ5xwQrP6AVK33357+cu//MvyjW98o+zYseMpc4cddlh5xzveUX7rt37LS6dA13Vr/W3v3r3l+uuvL//6r/9afvSjH5V77733afMnnHBCef/7318uv/zyMmrUqGdUF0ALnrMDDhb6O1rr6e3t7e3vRrD/OPzww8uSJUue8e8NHTq0/P7v/375yEc+4l/9AA5I3/3ud8s73/nOsmLFivh3pk+fXpYvX97BVgH88t7//veXL3zhC0/7kMZTeetb31r++q//uowbN64DLQNoR18HHIh++tOflk984hPl5ptvLkuXLn3a7C/7MO8XvvCF8q53veuXat8pp5xSvvKVr5QTTzzxl/p9gH/Xjf7u8TZs2FDe9773la9+9avP6Pf+5m/+prznPe951vUDpPbu3Vt+//d/v3z84x8ve/fujX9v+vTp5ctf/nJ5xSte0cHWAfz/urX+9v3vf7/8+q//elm2bNkzrueYY44p//AP/1DOPPPMZ/y7AM+G5+yAg4X+jtb8E1pUjRgxosycObOMHz++7N27t6xevbosWrSo/Mf3Xnbt2lX+5E/+pDz22GPli1/8Yj+2FuCZ+8u//MtyxRVXlMe/zzdixIhy6KGHlilTppRt27aVZcuWRf9aJcD+4Oabb37SmwmDBw8uhxxySJk+fXrZtWtXWbhwYdmwYUOfzN/93d+VBx54oFxzzTVlzJgx3WoywDOmrwMORLfeemv51re+1S91H3LIIWXKlCll9OjRZfPmzWXBggVl8+bNfTK/+MUvynnnnVeuueaacsopp/RLO4GBodv93ZIlS8rLXvaycv/99z/hv02fPr1Mnz69DB8+vKxbt64sWLCg+i/EAXTSu9/97vKFL3zhCZ+PGjWqzJ49u4wcObKsWbOmPProo33uXaxYsaL8P//P/1O+/e1vl4svvribTQYOUt1af3v44Yef8sWFSZMmlRkzZpTRo0eXFStWlEWLFj3hd88777zyb//2b+XFL37xM/yGAG15zg44WOjveDYG9XcD2P8ceuih5V3velf5yle+UubNm1e2bNlSHnzwwX1/ynnBggVlzZo15fOf/3w5/PDD+/zul770pfK3f/u3/dRygGfui1/8Yvnd3/3dPgOniy++uHzve98r69evL4888ki5+eaby913311WrVpVlixZUr7yla+U173udWXYsGH92HKA3IQJE8r73ve+ctVVV5V169aVxx57rNx2223lrrvuKmvWrCnXXXddOffcc/v8zi233FIuv/zy/mkwwC9BXwcMBC1fpho8eHC54IILyn//7/+9/PjHPy4bNmwoS5cuLXfffXf5+c9/Xu65556yYcOGcsstt5S3vOUtfX537dq15Y1vfGPZsWNHs/YA/EetXx7duHFjecUrXtHnxYWJEyeWj33sY+XRRx8ty5cvL3fddVe55ZZbysMPP1y2bNlSbrrppvJHf/RHZfbs2U3bAlDzjW984wkvLpxwwgnlqquuKhs2bCh33313ufnmm8u8efPKihUryp/8yZ/0uR+xc+fO8ra3va2sW7eu200HDnLdWn/r6ekpF110UfniF79YHnnkkbJmzZpy3333lVtuuaUsXLiwLFy4sFxxxRVl8ODB+35n27Zt5dJLL63+xS+A1jxnBxws9He01NP7+H9mmoPa3XffXU466aT4T7SsW7euvPSlLy133HHHvs8OOeSQsnjx4jJokHdjgP3bvHnzykknnVS2b99eSvm/f6rqyiuvLG9605ui31+3bl2ZOHFiJ5sI8Es744wzypo1a8of/uEflje/+c1l5MiRT5vfs2dPed/73lc+//nP9/n82muvLRdccEEnmwrwS9PXAQeiv/qrvyq/8zu/U8aOHVtOP/30cuaZZ5azzjqrnHnmmWX+/Pl9+qMjjzyyLFiw4BnXsXjx4jJy5MgyefLk+HeuvPLKJzxQ8tnPfra8973vfcb1A5TSnf7u373zne/s86+3nXfeeeWf//mfo36wt7e3bNiwoUyYMOGXrh/gmTjppJPKvffeu+/nM844o1x//fVl9OjRT/k71157bXn5y1/e56/G/M//+T/Lf/2v/7WjbQXo1vrbpz/96XLFFVeUd7/73eV3f/d3y6xZs6ptu+aaa8qrXvWqPi/ev/Wtby1XXnll9XcBWvCcHXCw0N/RmpcXeNbmzp1bnvvc5/b5V8t//OMfP+GNeoD9zYUXXliuu+66fT9//etfL294wxv6sUUA7Vx11VXloosuekZ/JWbPnj3lBS94Qbntttv2ffbmN7+5/MM//EMnmgjwrOnrgAPRI488Unbs2FGOO+64JyzSX3/99U0f5n2m3vSmN5V//Md/3PfzhRdeWK655pqu1Q8MLN3q766//vpy4YUX7rtHceaZZ5brr7++jBo16pduO0CnPProo0/4iy+33HJLOfPMM6u/+573vKd87nOf2/fzC1/4wvKzn/2seRsB/qNurb/dcccdZfLkyeXII498Ru371Kc+VX7rt35r38/Dhw8vq1evbv6XvgBa8ZwdcLDQ3/F0vMLCs3b88ceX008/vc9nc+fO7afWAGS+853v9Hlx4Q1veIMXF4AB5VWvetUzuplQSimDBw8uH/7wh/t89v3vf79lswCa0tcBB6LZs2eXE044Yb/814Xe8pa39PnZGh/wbHSrv/vd3/3dfTdBhwwZUr7whS94cQHYbz344IN9fj788MOjFxdKKeV1r3tdn5/nzZvXrF0AT6Vb62+nnXbaM35xoZRS3vve95bx48fv+3nHjh3l+uuvf8blAHSL5+yAg4X+jqez/90h44D0+H8hZPXq1f3UEoDM4/9U6Uc+8pF+agnA/uXxb7mvWbOmbN26tZ9aA9AZ+jqAJ2eNDzjQ3HrrreXOO+/c9/OrX/3qcvLJJ/djiwCe3tq1a/v8fMQRR8S/O3PmzD4/r1+/vkWTADqiW+tvQ4cOLS94wQv6fLZo0aLm9QC0ZA0OOFjo73gqXl6gie3bt/f5ecKECf3TEIDAkiVL+vzrHqecckp57nOf248tAth/TJw48QmfbdiwoR9aAtA5+jqAJ2eNDzjQfPGLX+zz8+P/ggzA/uY//uvgpZSybdu2+Hcfn50yZUqTNgF0QjfX3x5fl3U+YH9nDQ44WOjveCpeXuBZ6+3tLbfeemufzx7/514A9if/9m//Vvbs2bPv5wsuuKAfWwOwf1myZMkTPps8eXI/tASgc/R1AE/u5ptv7vOzNT5gf3fVVVf1+fn888/vn4YAhE455ZQ+P8+dO7ds2bIl+t1bbrmlz89nnXVWq2YBNNfN9bfH12WdD9ifec4OOFjo73g6Xl7gWfvSl75Uli5duu/n4447zmIZsF97/MDoec973r7/f+edd5YPfOAD5XnPe16ZOHFiGTVqVJk1a1a56KKLyl/8xV886UIbwEBy44039vn5yCOPLMOGDeun1gB0hr4O4Im2bdtWPvnJT/b57G1ve1s/tQagbvny5WXx4sX7fp41a9a+f9F88+bN5W//9m/Ly172sjJr1qwyfPjwMnXq1HLSSSeV97znPeWqq64qvb29/dV04CB2+OGHl7PPPnvfzzt27Cif+tSnqr+3Y8eO8ld/9Vd9PnvHO97RunkAzXRr/W3Lli3ljjvu6PPZscce27wegFY8ZwccLPR3PB0vL/CsXHnlleV973vfvp8HDRpUPv3pT5eenp5+bBXA03v8ywtHH3102bx5c3nHO95RTjvttPLXf/3X5e677y7r168v27ZtKwsXLiw/+tGPyoc+9KFyzDHHlN///d8vu3bt6qfWA3TWl770pT4/v/KVr+ynlgB0jr4OoK8lS5aUV73qVeWhhx7a99n5559f3vjGN/ZjqwCe3pOt8ZVSyo9+9KMyZ86c8va3v7388Ic/LAsXLiw7d+4sq1evLvfee2/53Oc+Vy655JJy5plnPuFfMQfoho997GNl0KD//zb9H/3RH5Urr7zyKfPr168vr3/968vcuXP3fXbppZeWSy+9tKPtBHg2urX+9vWvf73PX7AZN25cedGLXtSRugCeLc/ZAQcL/R01Q/q7AezfHnroobJo0aJ9P+/atausW7eu3HvvveU73/lOuf/++/f9t2HDhpXPf/7z5SUveUl/NBUgNm/evD4/Dxo0qLz4xS8ud955Z/V3t23bVj760Y+WW2+9tXzzm98sY8eO7VQzAbru6quvLj/+8Y/7fHb55Zf3T2MAOkRfBxyMdu/eXa6//vo+n23evLksXry4/OQnPyn/8i//UrZt27bvv73gBS8o3/zmN91IAPZrj1/jGzduXPn7v//78ta3vjX6qwq33357Oe+888pXv/rV8prXvKZTzQR4gnPOOad8+tOfLu9///tLb29v2b17d7n88svLZz7zmfLa1762zJkzp4wcObKsXr263HzzzeWrX/1qWbt27b7fv+iii8rXvva1fvwGAE+vW+tvW7duLX/6p3/a57Nf/dVfLUOHDm1eF0DCc3bAwUJ/x7Pl5QWe1mc/+9nyv/7X/3raTE9PT3nFK15RPvrRj5bnPe95XWoZwC9n7969ZdOmTX0++8AHPrDvxYWenp5yySWXlFe+8pXl8MMPL1u2bCl33nln+cpXvtLnT1n96Ec/Kpdffnn553/+5662H6BT1q5dW9797nf3+ezVr361P9sHDCj6OuBgtXnz5nLRRRdVc9OnTy9XXHFF+e3f/m0PewD7vfXr1/f5+eGHHy7vfOc79724cPjhh5e3vOUt5ZRTTimjR48uixcvLt/97nfLVVddte93tm/fXv7Tf/pP5Wc/+1k5/fTTu9l84CD33ve+t8yZM6d84AMfKPfdd18p5f/+RZnH/1WZ/+joo48uH/7wh8u73vWuPn+5AWB/0s31tw9+8INlwYIF+34ePXp0+cM//MPm9QCkPGcHHCz0dzxbXl7gWXvDG95QPvCBD+hggAPChg0bnvAvr91xxx2llFImT55cvvWtb5Vzzz23z39/4xvfWP7wD/+wvPvd7y5f/epX933+zW9+s/zd3/1deetb39r5hgN00N69e8tb3vKWsnjx4n2fjR8/vnzqU5/qx1YBtKWvA3h606dPL3/wB39Qfu3Xfs2LC8AB4fEvL/z7w7+llH3/gvmoUaP6ZN7znveU6667rrz2ta/d9/s7d+4sb3rTm8r9999fhgxx2wzongsvvLDceuut5Y/+6I/KX/7lX5Y9e/Y8ZXbmzJnlgx/8YHnzm9/sxQVgv9XN9bevfe1r5W/+5m/6fPbRj360HHrooc3rAmjJc3bAwUJ/x9OxssGz9vWvf72cc8455cUvfvET/kwzwP5m8+bNT/r54MGDy1VXXfWEFxf+3ZgxY8pXvvKV8rKXvazP5//zf/7P6M/QA+zPPvShD5Xvfe97fT773Oc+V4444oh+ahFAe/o6gKe3YsWK8oEPfKDMnDmzfOITnzDXBfZ7T7XOd+mll5YvfelLT3hx4d9dcMEF5Tvf+U6fh38ffvjh8vWvf70j7QR4Kv/7f//vMnv27PIXf/EXT/viQimlLFq0qLzvfe8rs2bNKl/60pe61EKAZ6Zb62+33HJLecc73tHns1e+8pXlN3/zN5vWA9AJnrMDDhb6O56Olxd4Wn/1V39Vent79/1v69at5bHHHivf/e53yzve8Y4ycuTIfdkbb7yxnHnmmeW2227rxxYDPL0RI0Y86efvfOc7y/Of//yn/d1BgwaVv/mbv+lzY/PBBx8sN9xwQ9M2AnTTpz71qfLJT36yz2cf/vCHyxvf+MZ+ahFAe/o64GA3YcKEPmt8e/bsKWvXri133HFH+dSnPlVOOumkfdlNmzaVD37wg+Vtb3tb2bt3bz+2GuDpPdk635AhQ8pnPvOZ0tPT87S/++IXv/gJf03185//fNP2ATyVXbt2lde//vXlve99b1m2bFkppZRJkyaVP/qjPyq33HJLWbduXdm5c2dZunRp+Zd/+Zfymte8Zl+/tnbt2vKOd7yjfOhDH+rPrwDwBN1af5s3b1659NJLy7Zt2/Z9dtxxx5WvfOUr1TEgQKd5zg44WOjveLZ6ev0TWjwL8+bNK294wxvKL37xi32fHXbYYeXee+8tEyZM6Ld2ATyVbdu2Pem/unbbbbeV008/PSrj5S9/efnBD36w7+c//uM/Lh/5yEeatRGgW7761a+Wt7zlLX3+Vd3LL7+8fOlLX7LIDwwY+jrgQHL99deXCy64YN/PRx55ZFmwYEHH6+3t7S2f/OQny4c+9KE+/eWf//mfezAO6IgW/d3v/d7vlT//8z/v89kll1xS/vVf/zX6/Z///Ofl7LPP3vfziBEjyoYNG8qwYcOeUTsAnql3vvOd5Ytf/OK+n88666zyne98p8yYMeMpf+df/uVfyhvf+Mayffv2fZ996UtfKr/+67/e0bYCJLq1/rZ06dJyzjnnlPnz5+/77Igjjig//elP/XVV4IDgOTvgYKG/o8ZfXuBZec5znlN++MMf9pkILlmypHz84x/vx1YBPLWRI0eWwYMH9/ls7Nix5dRTT43LOO+88/r87M1Q4ED03e9+t7ztbW/rczPhta99bfnCF77gYV5gwNDXAWR6enrKFVdcUT760Y/2+fxP/uRPyrp16/qpVQBPb8yYMU/47PHrdk/nzDPP7POvwG3fvr3cc889TdoG8FSuv/76Pi8uTJs2rXz3u9992hcXSinlsssuK5/5zGf6fPahD32oz788DtAfurX+tnbt2vKyl72sz4sLU6dOfcLzKgD7M8/ZAQcL/R01Xl7gWZsyZUr5kz/5kz6fffnLX+6fxgAEpk2b1ufn5zznOWXQoPySOGfOnD4/r1y5skm7ALrluuuuK294wxvK7t2793120UUXla997WtPeMEL4EClrwN45q644opy9NFH7/t5y5Yt5Rvf+EY/tgjgqU2fPv0Jnx177LHx7w8ZMqTMnj27z2fW+YBO+9SnPtXn59/+7d8uU6dOjX738ssv79PPrVmzpnzzm99s2j6AZ6Jb62+bNm0qr3jFK8p9992377Px48eX73//+0+4bwuwv/OcHXCw0N/xdLy8QBOvec1r+rw1v3Tp0rJw4cJ+bBHAUzv++OP7/Dxu3Lhn9PuPz/tXKIEDyc0331wuu+yyPn9i/uyzzy7f+ta3yrBhw/qxZQDt6OsAfjlDhgwpl112WZ/Pfvazn/VTawCe3uPX+Eqxzgfs33p7e8u1117b57NLL700/v1BgwaVV73qVX0++/GPf9ykbQDPVLfW37Zt21YuueSScuutt+77bNSoUeWqq64qp556arN6ALrJc3bAwUJ/x1Px8gJNTJgwoUyaNKnPZ8uXL++n1gA8vRNOOKHPzzt27HhGv/8fF+FK+b8LZAAHgrvvvrtcfPHFZfPmzfs+O/XUU8vVV19dRo8e3Y8tA2hHXwfw7Dz+XyG3xgfsrx6/xleKdT5g/7Zu3bqyYcOGPp8dddRRz6iMx+eXLFnyrNsF8Ex1a/1t586d5XWve12fF7WGDx9evv3tb5cXvehFzeoB6DbP2QEHC/0dT8XLC3TM0KFD+7sJAE/qtNNO6/PzihUrntHvP/7Px0+ePPlZtwmg0x588MFy0UUX9flXJI8//vjy/e9/v4wfP74fWwbQjr4OoD1rfMD+avLkyWXmzJl9PrPOB+zPnuwFqyFDhjyjMh4/NtuzZ8+zahPAM9Wt9bc9e/aUN7/5zeV73/vevs+GDBlS/vEf/7FcdNFFzeoB2F9YgwMOFvo7SvHyAo1s2rSprF27ts9n06dP76fWADy9V73qVWXQoP//Ejh//vwn9GFP5/bbb+/z85w5c5q1DaATFi5cWF760pf2eSjjqKOOKj/84Q/L1KlT+7FlAO3o6wDaePyfbLbGB+zPLrvssj4/P37d7umsWLGiLF68uM9nxx57bJN2ATyZJ3tBaunSpc+ojMf/pQXzXaCburX+1tvbW97+9reXf/7nf9732aBBg8rf/u3flle/+tXN6gHoL56zAw4W+jueipcXaOKqq64qvb29+36eOnVqOeSQQ/qxRQBPbdq0aU/4U6Lf/OY3o9/dvXt3+da3vtXns/PPP79V0wCaW7ZsWXnJS17S54GMww47rFxzzTXlsMMO68eWAbSjrwNoo7e3t3z3u9/t89nJJ5/cT60BqHvNa17T5+dvf/vbZe/evdHvfuMb3+jz8/HHH+/mKdBRw4YNe8L902uvvfYZlXHNNdf0+Xn27NnPul0AiW6uv/3mb/5m+bu/+7s+n332s58tb3nLW5rWA9BfPGcHHCz0dzwVLy/wrG3btq185CMf6fPZJZdc0udfNQfY37z73e/u8/PHP/7xJ/2TzY/3f/7P/ynLly/f9/O4cePKy1/+8ubtA2hh7dq15aKLLiqPPPLIvs+mTp1afvjDH5ajjjqqH1sG0I6+DqCdv/3bvy0PPPBAn88e/6+aA+xPzjvvvD5/FXXRokXlyiuvrP7e1q1byyc+8Yk+n/3Kr/xK8/YBPN5LXvKSPj//1V/9Vdm9e3f0uzfccEP5+c9//rTlAXRCN9ff/ut//a/ls5/9bJ/P/uIv/uIJ93YBDlSeswMOFvo7no6jgH0+/OEPl1tvvfUZ/c7atWvLZZddVh566KF9nw0ePLj8zu/8TuvmATT1pje9qZx00kn7fn7ooYfKu9/97qf9l9luvvnm8uEPf7jPZ+973/vK+PHjO9ZOgF/Wpk2byite8Ypy33337ftswoQJ5Qc/+EE5/vjj+7FlAO3o6wCe6IYbbih//ud/XrZu3fqMfu+f/umfynvf+94+n73hDW8oRx55ZMvmATQ1ePDg8t//+3/v89nv/M7vlDvuuOMpf2fPnj3lHe94R5k/f/6+z0aPHl3+83/+zx1rJ8C/e/y/Gn7vvfeW973vfdW/GjNv3rzy5je/uc9nxxxzTHnhC1/YvI0A/1E3198+9rGPlT/7sz/r89lHPvKRcsUVVzStB6AFz9kBBwv9HZ3Q0/sf/yYHB7VTTjml3HXXXeWss84qb3zjG8uFF15Ynvvc55ahQ4f2yfX29pYHH3yw/NM//VP51Kc+VVavXt3nv3/wgx8sH//4x7vZdIBfyjXXXFMuuuiiPn+e6qUvfWn5sz/7s3L66afv+2zDhg3li1/8YvnIRz5SNm/evO/zY489ttx2221l7NixXW03QOKCCy4o119/fZ/P/vRP//SXuqF5+umnl4kTJzZqGUA7+jrgQPXTn/60bNu27Qmf33XXXeWDH/zgvp+nT59e/v7v//5Jyzj00EPLCSec8ITPv/3tb5fXvOY1ZcKECeW1r31tec1rXlPOPPPMMn369CdkN23aVK677rryuc99rlx99dV9/tukSZPKL37xi3LEEUc8068HsE8n+7v/6Pzzzy833HDDvp/HjRtX/vRP/7T8+q//ehk3bty+z2+77bbyoQ996AljyM997nPlN37jN5KvBPCsXXjhheW6667r89k555xT/viP/7icd955ZciQIfs+X7NmTfnyl79c/tt/+29lw4YNfX7nn/7pn8rrX//6rrQZOHh1a/3tyiuvLJdffnmfz84555wn/Gu9iWT8CPBsec4OOFjo7+gELy+wz793Mv/RsGHDymGHHVYmTJhQhg0bVjZt2lQee+yxsmnTpict421ve1v50pe+5E+7AAeMj33sY+W//Jf/8oTPZ8yYUQ4//PCyZcuW8sgjj5SdO3f2+e+TJ08u1113XZ+/3gCwP+np6WlW1nXXXVfOP//8ZuUBtKKvAw5Us2bNKgsXLnxWZbztbW8rX/7yl5/w+b+/vPB4U6dOLVOmTCnjxo0rO3fuLGvXri2LFi0qT7Y8PGHChHLNNdeU00477Vm1EaCT/d1/tGzZsvKiF72oz19TKOX/3uOYPXt2GT16dFm8eHFZvnz5E373Xe96V/n85z//rNoI8EwsX768nH322U/os0opZcyYMeWoo44qI0eOLGvWrCmPPvrok47XrrjiivIXf/EX3WgucJDr1vrb5ZdfXq688som9STjR4Bny3N2wMFCf0cnDKlHOJjt3LnzSRfOHm/cuHHlz/7sz8p73vOeppNXgE77vd/7vTJq1KhyxRVXlF27du37fPny5U96M7OUUubMmVP+9V//tRxzzDHdaiYAAAA8K6tWrSqrVq2q5i666KLyuc99rhx11FFdaBVAG4ccckj58Y9/XF7zmteU2267bd/nO3fuLHPnzn3S3xk0aFD5oz/6o1/qX/MFeDZmzJhRbrjhhvLWt771Cf+a+ebNm8s999zzlL87dOjQ8t/+238rH/7whzvcSgAAninP2QEHC/0dz5bXWNjna1/7WvnYxz5WXvrSl/b5M8pPpaenp5x88snl4x//eJk3b15573vfq4MBDkj/+T//53L33XeXN77xjU/4k1b/0VFHHVX+1//6X+Xuu+/24gIAAAD7pZe97GXlm9/8ZnnXu95V5syZE63XjRs3rrz5zW8u11xzTfnBD37gxQXggHT44YeXn//85+XTn/50mT179lPmhg8fXl7zmteUu+66y4sLQL854ogjyjXXXFO+/vWvl/PPP7/6r0+OHz++vPe97y333HNP+b3f+z33ZAEA+pnn7ICDhf6OTujpfbK/M8lBb+/eveXhhx8u8+bNK4sWLSobN24su3btKmPHji3jx48vs2bNKqeddlrUGQEcSDZu3Fh+9rOflYcffrhs2LChjBkzpkyfPr2cdtppZc6cOf3dPAAAAHhG1q9fX+6///4yf/78snLlyrJly5YybNiwMn78+DJ58uRy0kknlWOPPdbNA2DAuffee8udd95Zli5dWvbu3VumTJlSjjzyyHLOOeeUUaNG9XfzAPrYtGlTue2228qjjz5a1q9fX7Zv317GjRtXJk+eXE4++eRywgknVF9wAACgf3jODjhY6O9oxcsLAAAAAAAAAAAAAABAR/nnGQAAAAAAAAAAAAAAgI7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB01JA2+613vqmYmTpwYlTVu3LhqZvTo0VFZI0aMqGaGDRtWzQwdOjSqr2VZQ4bUN//gwYOblNOyvm3btkX1Jfswqe+Z5GoGDer++zo9PT3VTG9vb7P69u7d26yspF1nn312s/r2B1/72teqmfR4bLlfEy2PtVbnXCnZMZmcm3v27InqS3M16bmUbNN0u++PbU/LSnK7d++uZtJ+eseOHdXMtddeG5U1ffr0auYLX/hCVNaBJNk+La+b3b4+JX1iKdl37I/+oJVu15ec56lWfWKq5bb6+te/Xs18//vfj8pK5ljJ/KqUUoYPH17N/OQnP4nKOlDce++9/d2EX1rLvq7l8Z3UmfSbad/aaozbcjyWltWqXf0xtku2Q7L2sXTp0qi+j370o9VMerwnuVtvvTUq60CRXFO6vXZUSnaMJPWlY9J0PS6RfMekXS3H08mxnZ4nSV+QlpVIxojpMZrsm7TtrcabLfdzy/WYmTNnNitrf/C///f/rmaSewWldL/vScbhaR+W5NLjKGlXt7dVUlbLewot1w6SbdWyb023e8t+JdFqLTjNzZgxIyrrQPKJT3yiWVktr1H749inpeRcablW1bK+bp/niW6v65XSbk7c8p5IS1dccUVX6+u0t7/97dXMlVdeGZV1wgknVDNHHXVUVFYyPkoyo0aNiuobM2ZMNTN16tSorLFjx1YzyXhl5MiRUX1J35OM/9Lngn7xi19UM8cdd1xU1vjx46uZ5DrUcq0l1e0xZ8sxdeL0009vVtb+IOnHkj6llGyc1e1n1VqO61uW1W3dvgfebS3v/abfL9mmLe8LJf3YX//1X0dl3XnnndXMqlWrorIOFMl3bqnbayvdHveX0u74btmndPt+Ziopq2U/luj2PfCWc9iW+/Ciiy6qZva/qzoAAAAAAAAAAAAAADCgeHkBAAAAAAAAAAAAAADoKC8vAAAAAAAAAAAAAAAAHeXlBQAAAAAAAAAAAAAAoKO8vAAAAAAAAAAAAAAAAHSUlxcAAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOmpIGhw+fHi9sCFZcYMHD65mBg3K3qtoVVZaX5Lr6elpVlayTdPtntQ3YsSIaub73/9+VN/pp59ezcycOTMqK7F3795mZaX7cH+sLz2WEy236YFi6NCh1Uy3j49S2u7Xbkv66US63ZP6kmN7z549UX29vb1N6isl+45Jfem2SspK91+yvZLrVbqtktzRRx8dlTVnzpwoN9C0HNO0qi/V6lxJdfva2vL6m5zDO3fujMpKcsOGDYvKSrTsMxJpWcnxMGvWrGpm0qRJUX3J+HzXrl1RWdu3b49yB5uWc8HU7t27q5mkr0vb1O1xfcttlfTnSX3p2K4/xvo16fZsee1LjplknWjlypVRfTt27KhmkrlaKdn5NdAk1/t0XN+yrFbrcS37lLTtSV+QlNVybtbyupDk0m21bt26auaBBx6oZtJxytlnn13NJOOnUrLt0PIa2u052ECzP55zaa5VJs2lfUGrslren+j2OdByW7VcZ2t1HeoPLa/tB2ufOGrUqGomHfN2+1hK5l3puD7R8n5souU4OBljdLu+lvrjnlar+z7pdm95b+hgvB+bjP/T7ZL0m90eH6XrtYccckg1M2bMmKisBQsWVDPHHXdcNdPyHBg/fnw1k84F77vvvmrmiCOOiMqaOnVqNZNca7dt2xbVl1z70v3ccm5B57Wcxybzrpbrf91+zi6dV+6Pun0fOT1mNm3aVM0k63qHHXZYVF/LZ3Ba3SNO5x7JNfSRRx6Jyho5cmSU48m1nMO2umfWcs6ctml/nB+0XNdLtkPL+7otrzFJfenzN63q64915VbH6IH7NCwAAAAAAAAAAAAAAHBA8PICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI4akgYHDx5cL2xIVlySS+orpZRBg+rvX/T09DRpU1pW0qa0rCTTUrLdV65cGZW1YcOGambv3r1RWck2Tbd7t7VqV7qtWtpft2knpX1BtyV9QW9vb5Ny+kPS9vS60O36krL27NkTlZWc50l9aX+RlJVKtlfSrt27d0f1jRgxopoZO3ZsVFZa50DT7T4+ra/lcdltrfqWdFsl16xt27ZVM3fddVdU32233VbNnHHGGVFZSb+4a9euauacc86J6kvKSiX7Z/bs2dXMxIkTo/q2b9/eJPNMcgNJcp60nL+lfdjQoUOjXE06tkvOubTtreYlLa8LLfdNS622Vcu5YMtjJilr0aJFUX3J2G7Lli1RWfvrnK6Tur2+1O11r7S+ZJyVbodWbW85r0z6gp07d0b1DR8+vJqZMGFCVNa6deuqmWQt8ac//WlUXzLOmjVrVlRWqzXjdM7fcl2jP9YJ+1vLvm5/XONvWV96rCW5lnPYVtshHUu3vC4kWh6jLfuLxP66RnSwanVutrY/jrNbHkvdPi6Tvqzlela3xw4t60vLSs6LVusxpbRb3yylf87p/rZ+/fpqJr1ujhw58lm25plJ+sP0uD3++OOrmXRt5eGHH65mTjjhhGqm5fGYrIHffffdUVnJ8TBt2rSorGT/JNvh3nvvjepL5s2ve93rorKSfuVg7FMOZN1eq0pzydio5XN2adsP1LlEel1ouX6QPCvxrW99q5q5+OKLo/qSPjhdu0wk2zQ9RhcvXlzNJPfcSyll6tSpUW4gafWsUFpWy76u21r2dck2TdetW+n2Olsp7e4jr127Nqov6QsOPfTQqKxWz6r1x7He6np8YF7VAQAAAAAAAAAAAACAA4aXFwAAAAAAAAAAAAAAgI7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjhqTBwYMHN8m0Lqunp6eaGTSo/o5GkklzSZvSstJ2JYYMqe/u7du3VzPr16+P6kv2Yfr90m06kKXbau/evc3q7O3tbVbWgWLYsGHVTMtt3PIc77aW2yGRbqs9e/Y0qS/9fsl50rIPS+prtQ1KybfD7t27q5nkOpScg2l9adtXr14d5Qaa5LhMx2Mt+4OkXd0+71JDhw6tZoYPH17NbNy4Mapv/vz51cydd95ZzTzyyCNRfY8++mg1s3Llyqis0aNHVzNbt26tZo4++uiovhkzZkS5VsaPH1/NjBgxIipr+fLl1cymTZuispLjb6BJ+7FW0r6n231UyzFnUlZyXUivHck+TMpqOU9vWVZLyfVx165dUVnJuC0Zjy1atCiqb8eOHdVMej5v3rw5yg0kyf5Kt19SVnpsJ3W2bHu319Ba1pdco9esWVPNzJ07t0VzSimlnH322VEu6VeS/ikdA993333VTLodku0+Z86caubII4+M6mt1DT1YJdff/rjet1oD7497K0lf12qOXkq2HZJ5ddr/tlw7aHW9ajlfaDmn6HZ9Le//DUTp+mii5bWnVbvS+lr21YlkTX3kyJFRWTfddFM1k3y/M844I6ovmU8l/VhLLcc0++v4qOVaxMEoGf+n1/xk/NBynNhqraqUrO3p+ZusuSfSe4xjxoypZpK2p/foJkyYUM2MGjUqKitZ00rGkkuXLo3qmzZtWjWTjo/Stb2almsa3V6DP5B0e92r5byy5fNsrZ7rS8vqtqS/aHnOpePyZN0r6VOWLFkS1Tdz5swm9aVarldMnTq1mkn68lLyOcNAkuyLlvORls9PtpwzH8jP/yW6PS9Lr2nJ2DUZc2/bti2q7/rrr69mXvayl0VlJc+wpO1KJMdo2m+2Oh4G9lkDAAAAAAAAAAAAAAD0Oy8vAAAAAAAAAAAAAAAAHeXlBQAAAAAAAAAAAAAAoKO8vAAAAAAAAAAAAAAAAHSUlxcAAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOioIWlw8ODB1cygQdm7ED09Pc3KSto1dOjQJuWUUsqQIfVNlpaV5Fpuq7Fjx1YzixYtqmY2b94c1Td+/PhqJvl+peTfcX+UfsdWkm21d+/eqKxut31/kHznpE8pJdvOLY/tbteX9nWJbrc9kR7/vb29zcpqVV+6b3bu3FnN7Nq1KyoruT7OmjWrmrnnnnui+ubPn9+kvlJKuf7666PcQNPyuEyOueTYbSn9frt3765mxo0bF5U1YsSIambNmjXVzNVXXx3Vl5wvq1atqma2bt0a1Zfk0jHG+vXrq5lk33zuc5+L6vsv/+W/VDPDhw+Pykq+45gxY6qZY445Jqrv5ptvrmaS/ryUUqZPnx7lBpKkL0j7p2Qs0nL8kGg5rk/HWmmdNd2ea2zfvj3Kbdy4sZpJ91/Sj+3Zs6eaScZZpZQycuTIaibpn0opZdiwYdXMtm3bqpklS5ZE9Y0ePbqa2bFjR1RWy3nKgaLlXKllf9GqXS3XjtKyWh1HaTnTpk2rZpKxWLpmN2/evGrm6KOPjspK+tekP0zHMw8//HA1c+SRR0Zl3XnnndXMz372s2rmQx/6UFRfMq84kNdAOy05n9JzrmV/kZTV7f4pLavVeKzV+LCUbB0qGaeUkm33dJzVcrt3W7IdkvFtf9z/O1glx2W3x38t6+x2/9pSct+zlGz9L1nXu+CCC6L6Wt5fabVN02tDMk7s9n20VMtztWW7DhTJeZKst5eSreum48Skj0rWctJ9n65JJ5J1k6Rd6bZK1piSOeq6deui+g455JBqJm17cq9/5cqV1Ux6b+WUU06pZtJ+oFWf2O3rwsEq6VP6Y2zUaszesm9NdXvtN+nzk++Xzj2TsVG6PZPrwqZNm5qUU0r2HVseCy3rO/TQQ6uZiRMnRmWl14aBpOV+bbmGllzvk+tv2u90+9mxVus9LetLJds9bXuSa/m8dzK+TZ6/LiW7j5Hcf0nbnlzTuv1MsZEmAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI4akgYHDx7cJNO6rEGD6u9f9PT0RGW1krSplHbbobe3N6pv3Lhx1cymTZuatKmUUiZMmBDlEt3eh4l0Pyf27t3brL6WZR2MkuM7PR6TXMtju2V93T5GkuM27euSfZjUN3To0Ki+PXv2NKmvlFJ2794d5VqVs2PHjmpmypQpUVkjRoyoZu69995q5nvf+15U3+mnn17NTJ06NSqr5fXqQNLt83x/vfYMHz68mhk5cmRU1urVq6uZG2+8sZr56U9/GtW3cOHCambIkHi4X7Vly5ZqJu2rkz42OWbWr18f1Zf01ekYN5Fcb88444yorK997WvVTPL9Sill48aNUW4g6Xbf03Kc2G3p+Zu0Pdnu6XGbtqtVfcOGDatmkjFUKdmYbMOGDdVMMk8vpZSdO3dWM+k1bc6cOdXM6NGjq5l0nLV48eJqJu3D0rH3QJKcly3X2Vqu/yVjlZZ9a8uxUWLt2rVRLhlnJeOnQw89NKovGUdu3749KivJJdsh3Tdnn312s7Luu+++auahhx6qZh577LGovpNPPrmaSefz++v8qpNajUHSslquobXKlNL23koydhg7dmw1c9RRR0X1LV26tJpJxg4TJ06M6nv44Yermc2bN0dlJWtMyThy165dUX0t73u1Kmt/XRMfiJJzOO0zkmtiy2tKUlY6Xu92u1r1iaVk47Zly5ZFZSWS/ifdni334f5YX6t7MKl0XHowzmOTOUKy7lBK94+jluvIyXpVer8yuU+XSK/TyfmUjLWStbFSsvlu0h+mknnetGnTorKStqfrja3mAy2vCzy1bj9n1+0xYtpfdPsZnJbltHr2JD3Hk+2eXh+T8W3Sb7bcNy2vocm9o3TsN3ny5Gom7fOTZwEGmm6vYaRariW20u1xf7fXX1rd0y0lb3ur5w2TezRpWUn/W0q7frM/1tla7WsjTQAAAAAAAAAAAAAAoKO8vAAAAAAAAAAAAAAAAHSUlxcAAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAdNSQNDh06tJoZPHhwVNagQfV3Jnp6eqKy0lyrcpLvmGyrtKxkW40cOTKqb9euXdXMokWLqpkRI0ZE9SXtSr5fmtu7d2+z+pLjIS0rkZ473ZZs04FmyJC4W6zq7e2tZlr1Yan0uO32vk/6zaQPKyXbpsl+3rlzZ1RfIt2ee/bsqWYmT55czYwaNSqqb9u2bdXM0qVLo7Luv//+auaBBx6oZk488cSovjlz5lQz6T487bTTotxA07L/6fZ1M6kvOZ9KKWX8+PHVTHpt+O53v1vN/OxnP6tmVq9eHdW3Y8eOJpm0zxg9enQ1k+7npKxp06ZVM6985Suj+saOHRvlEq2Ov6lTp0b1vf71r69mHn744aisRx55JMoNJMk4O71Od3vc1tL+2Pa0n05yw4YNq2aSsXkppaxbt66amTFjRlTWqlWrqpm1a9dWM0cffXRU3/Lly6uZjRs3RmXddNNN1cyRRx5ZzYwbNy6qL9nP6bma7uuDTdoPtFyzSyRlpWsmLddWkrKSzIIFC6L6br/99mpmwoQJ1Uw6n0rm11u2bInKOvTQQ6uZ5PxN+7pjjjmmmnnwwQejspJxftL23bt3R/Ul51fLedNAk5xzLe8ptOw3W90HSHPptXDKlCnVTHJupttq9uzZUa6VZN65cOHCqKz77ruvmjnppJOqmZkzZ0b1Jfsw7XtaHX8tx1j74/xkf5LMb9K1qv3xutIf98Na3ffp9n2TtN0t72u1HJ8nWt3/TSXbquXYLpXWOZBs3ry5mknWh0tpO85udd1Mz5PkPl3L4yMpK13LSe7trlixoppJtkEp2Zw43e4rV66sZpI191NPPTWqL9lW6X5On0WqaTn/4Km17J+Sa1jLMWKrtbGW9aVlJXOXTZs2RfUlZZ188snVTHrv9zvf+U41c8YZZ0RlJfch0+f/Ei3XPhLJvknHkckcLJnzl1LK17/+9Sg3kHT7fkG3tWxTt6+radtbnU/9sf+Svid5HqblunL6bEq3nyvdH8sy0gQAAAAAAAAAAAAAADrKywsAAAAAAAAAAAAAAEBHeXkBAAAAAAAAAAAAAADoKC8vAAAAAAAAAAAAAAAAHeXlBQAAAAAAAAAAAAAAoKO8vAAAAAAAAAAAAAAAAHSUlxcAAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOmpIy8IGDx7cLJeWNWRI/St0u76enp6orFbGjRsX5TZu3FjNPPjgg9XMzJkzo/pGjBhRzaTbKtnu5Pbs2dPfTdhvDRrU3Xe6ut1fpNI+sZVku6dt2rVrV5NM2u+MHDmymtm5c2dU1tatW6uZHTt2VDNr1qyJ6nvggQeqmWXLlkVljR07tpp51ateVc1Mnz49qm/79u3VTNrXJftwIEr6n7RP3Lt3b7OyWunt7Y1yybG7YMGCqKz58+dXM6tXr65m0mvD+PHjq5mkv0v711GjRlUz73jHO6KykvHkhAkTqpmhQ4dG9SXbIT1mEsk2Tds+ZsyYauayyy6LykqvRwNJcj61HPekx1Gr4y1te7eP7+RYS9vU6vpx//33R7mrr766mjnmmGOisjZs2FDNrFixoppJt8Ho0aOrmbTvSbbXL37xi2omue6Vko1x0/F5Mk4caFqueyXHW3pMJvus5Vyw5fg2OZ92795dzQwfPjyqL1lDu+uuu6qZyZMnR/Ul4/fkvCwlGyMm22HGjBlRfYl0zJPkkmMmGZeXkl37uj1vGmjS7Zf0F+l1p9XaXtr2bdu2VTOHHHJIVNbs2bOj3P4mXe/ZtGlTNZP2FytXrqxm/t//9/+tZk466aSovjPOOKOaOfTQQ6Oykv486Z/SYz3J7a9r4vuLVmOoVLo/Wo4TW0nra9WutP9J1tQnTpxYzSRj0lLajWlSSVnJeDPV7bJa3pNu2faBJpm7p+fA/tr3JJLjLT0mk3FikknnsclcveUzCbNmzapm0mMmWa/avHlzNZOuEba8L93q+EvLabl2fjCOAVven2g5zm61HpfW17KsZNxz+OGHVzNz5syJ6kvWwG+44YZq5rTTTovqS9bvf/KTn0RlJWtt69atq2Zaro+07FOSa0za9qSso48+OirrLW95S5QbSJI+peWaQst7ni3HdS3XVlpp+bxPS8m5mbZp2LBh1Uxy/6XlvZzk3lEp++ezmV0/RrtaGwAAAAAAAAAAAAAAcNDx8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB01JA4OKQeHTx4cFRWkkvL6unpqWYGDaq/o5FkWtZXSvYdk7KGDh0a1Tdq1KhqZvLkydXMxIkTo/rWr1/frKxEeswkkv3c29vbrL7Enj17olx6/CWS7TDQJH1dt/d9KfvnMZlKtmny/Xbt2hXVl2yH8ePHVzPDhg2L6kv6uuXLl0dlPfjgg9XM1q1bq5mRI0dG9SV98HOf+9yorLFjx1Yzu3fvrmbS/ZwcV6mW14+BJr0OtDrPS8muY8k1MRn3lFLK8OHDq5mlS5dGZSXHeMu+utU1f86cOVHuV37lV6qZ4447Lipr79691UzL7dnyPE+Ov6S+NWvWRPXNnTu3mnnRi14UldVynDiQ9MeYN9kXyfHdsk9Jt8P27dublJXWN2/evGomGWvdf//9UX1btmypZm666aaorKSvS1x//fVR7tBDD61mkv1XSimrV6+uZpLvl65XjBgxoppJj/eW48QDRcu1qpbnb6uyWvbT6Vxp48aN1UxyTCbrbKWUMm7cuGomGYMsWrQoqm/MmDHVzNVXXx2Vdcstt1QzSR984oknRvUl2zTZnqWUsmPHjmpm9OjR1UzL9c2W59dA0+01z5b7IpkfpGu/hxxySDWTzvH2R8l2SMYppZSycuXKambZsmVRWck6YbKfb7vttqi+pN98/vOfH5V17rnnRrmalmOxg7EPeyaS/q7lml1qfxxnd3udIx1jzJo1q5p5+OGHq5n02pCsg7ZcG0vGUC33TbJGmDoY2nWgSK4ryVpBKt3GSS5ZD0nPuWRuNnPmzKisCRMmVDM7d+6sZtJje9WqVdXM4sWLq5lk/l1Ktu61bdu2qKxkzf3www+vZqZOnRrVt3nz5momXUNLJNfslueEsd1Ta7n9kn6l22sKLfd9+mxGklu7dm01kz6/kfTBydrYwoULo/qS+6zpGn9yXyHpp5PnQErp/vNKyTnRsk3pdmg5fhlIWj4rku7Xbl+fWt7XTdqejElbXmOSsUo6h03GRuvWrYvKmjFjRjWTjBE3bNgQ1Zd8x3Q7tHp2PJUcf+k8plX/evDNhAEAAAAAAAAAAAAAgK7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB0lJcXAAAAAAAAAAAAAACAjhqSBocOHVrNDBqUvQuR5Hp6eqKyBg8e3KSstL6WbU/KSr7fkCHZbkzKOu+886qZESNGRPXdcMMN1cwRRxwRlfX85z+/mtmzZ09UViLZpsn2LKWUvXv3VjO9vb1N2pSWlUrP6YFkf/3OSb/Sct+n/VgiOTe3bdtWzaT7ZvTo0dXMpk2bqpkNGzZE9Q0fPryaWblyZVTWli1bqpnTTz+9mpk+fXpUX7JNd+7cGZW1e/fuKFeT7uekb0376YNVy2tdtyV91IQJE6Ky1q5dW83Mnz8/Kmv58uXVTHKep5LtkPRRv/ZrvxbVd/zxx1czW7dujcpKzuFuX/tSrcYKadsPPfTQaiY93u+8884oN5C0HNN0u76W89jknNu1a1dUVnIOjBo1qppZtGhRVN8dd9xRzdxzzz3VTNo/Jedmsj3TOkeOHFnNLFu2LKpv/fr11cywYcOispIxYHL8TZ06NarvpS99aZM2lVLKd7/73Sg3kCRjtvT61XIdqtW6V8v1xnR8u2LFimom6TfTbZX0K8mca+HChVF9xx57bDUzb968qKzPfe5z1cwpp5xSzZx77rlRfcl3fPjhh5uVNWvWrGpm/PjxUX376/zqQNFyXT7Jtew3W85t5syZE+X2R8m1fMGCBdVMus42d+7caiY9ZpI+PzkWJk+eHNW3efPmauaHP/xhVFYy7v7VX/3Vaia9piX21zX4/UW3x0fd1nL9Ny0rOdeTuVJ6f7TV2C65N19KKatWrapmbrnllqisZDsk87f0nm1yvCf3fErJ1l2TfZPO+ZPjr+V8YKBJtl96zrXcF4lkLTbtn9atW1fNJGtHpWT9SnI/ZPXq1VF9yfhozZo11cwLXvCCqL5kO9x9991RWcmY87WvfW1UViLpz1s+89NqjvJMcon9cVzSaS37p2RfpOsOrcabLZ9hmjhxYlTWmDFjqpmkH/v7v//7qL6jjz66mknWwK+99tqovlNPPbWaSbZBKaUcc8wx1cwDDzxQzaT3tpN+Opnr9oekn96xY0dUVqvnZg4kLe9ndvsZ30Q6Vm95zUzqTOZuLe9nJn3rpEmTovo2btxYzfzoRz+Kykrmiy9+8YubtKmU7HnDsWPHRmW1WvdIj72kf0rLajW/OvhGhwAAAAAAAAAAAAAAQFd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6akga7OnpaZIppZTBgwdXM0OGZE0bNKj+/kWrTCnZd0zLSnLJtkoNGzasmtm9e3c18w//8A9RfdOnT69mbr/99qis0047rZrZtm1bNbN8+fKovhNPPLGaaXm89/b2RmUl9u7dW82k51dyPAw06X7tdn3JMZL2Pa3qS865UkpZt25dNTNmzJhqJunDSill0aJF1czKlSurmSOPPDKqb/369dXM9u3bo7IuuuiiambcuHHVTLpv9uzZU820vA4lx1V6TiRtT/vWbp/3+4uW37tlWcl+Gzp0aDWT9CullPLoo49WM7t27YrKSuqcOHFiNZP2GVu2bKlmkm01evToqL7kvGs5pk6OhWTc07qsVsf7hAkTotyZZ55ZzVx33XVRWY888kiUG0gO1j7+8ZJzIL3mJ8fu5s2bq5kVK1ZE9SX7cPz48dXMqlWrovqSvm7EiBFRWUcffXQ1k5zj6Zjm1FNPrWbSuWDSXyT7Jh3DP+c5z6lmNmzYEJW1YMGCKDeQtFyrOpD7zeHDh1cz6fU+6RMXLlxYzUyaNCmqL7Fjx45qJh1HHnbYYdVMMvdMJf3mEUccEZWVzOeXLVsWlTVy5Mhq5uSTT25STilt58QHo5b3J1quoSV1JuOLdH5wIFu6dGk189BDD1Uz6bV+69atUS6R7OfkOpTM0UvJxmxjx46Nyrrvvvuqma997WvVzNvf/vaovp07d1YzLa/HA1E63+i2Vn1ny3trLfvzpKx0rJWM25I1/GTcU0q2Rjhr1qyorG984xvVzJQpU6qZs88+O6rv5z//eTWTzonPOOOMaibZN+m90aS/S/rgUkqZOnVqlBtIkutm2h8m5296HCVr5a94xSuqmZtvvjmqLzlG0rYnfdSmTZuqmbTvSfqCyy67rJo55JBDovqStaq77747KitZr0rWqtJ7R8nYLr2mJdfH5FrbH+Osg3G+u7+OZ5N9ka4jJ5LjO50j3HDDDdVMsu6VzsFvuummaubyyy+vZmbPnh3V98lPfrKaOeecc6Kyzj///GomubedPtd3yy23VDMnnXRSVFb6vEtNsh5TSnb8peu8z3/+86PcQNJyzW5/lF6jk+Mt7VuTZ1iSTDJHKiUb09x6663VTHov9thjj22SKSWbS914443VTLrOlhwP6TWm2/cLWj2jk5aV8JcXAAAAAAAAAAAAAACAjvLyAgAAAAAAAAAAAAAA0FFeXgAAAAAAAAAAAAAAADrKywsAAAAAAAAAAAAAAEBHeXkBAAAAAAAAAAAAAADoKC8vAAAAAAAAAAAAAAAAHeXlBQAAAAAAAAAAAAAAoKO8vAAAAAAAAAAAAAAAAHTUkDg4pB4dNCh7F6Knpyettmrw4MFdy7Qua/jw4dXMIYccUs3s3bs3qm/t2rXVzJYtW6qZTZs2RfVt3769mkm+XymlPPzww9XMqFGjqpkHH3wwqu95z3telOumdD8nx19vb2+zsgaalv1T2icmknbt2bOnmlm9enVU3/z586uZnTt3RmWNGTOmmkn6lbTv2bp1azUzffr0ZvUl59N5550XlTVs2LBqZtu2bdVMy+tx2l8kdu/eXc2kbU/adTD2Yc9Ey+3Tsu9M9u348eOrmeR8KqWUjRs3NsmkkvHKiBEjmtU3duzYambatGlRWcl1JpUcMy2Pq2QclZ4TyTGa1Ddy5MiovmOPPbaaWbJkSVTW7Nmzo9zBpttjtlKy8ylp144dO6L6krKSOX8ppaxfv76amTdvXpNMKdk8Ntme6TmXzGN37doVlfXGN76xmnnxi19czSTz9FKydqVju5kzZ1YzyXzgvvvui+pbuXJlNXPTTTdFZU2cODHKHWxajutTSZ/YckyanOfp+Zv0K2vWrKlmJkyYENWXtCvZnsl8uJRsvpuMW0sp5ZRTTqlmLrvssmb1Jde0E088MSpr9OjR1cyKFSuqmXT9IBmbtxyXDDTdnkOkWu2zlvPAltatW9ckU0opDz30UDXzyCOPVDPpHD0ZQyVjzVJKOeuss6qZpF1Dhw6N6kvWNJJxaynZteiOO+6oZtJ7OZdcckk1k16PD1ZJv5L2d92e7x7I67HJ2nW63pjcY0zOu6997WtRfW9961urmRe+8IVRWatWrapmvv71r1czRx11VFRfcsx89rOfjcpK+v2kP08l1+7bb789Kuu00057ts054CTXxPS62bKvS+rcvHlzNTNnzpyovuS+7fLly6OykjnxuHHjqplk3lJKKUceeWQ1c9hhh1UzyVpjKdl2SJ4pKaWUU089tZpJtlU6B0+O0Zb3dpO+NR1L7K/PThwoWo6fkvX7dI2/1X5tOfZLx1nJ/bAHHnigmknuvZVSyt13313NzJ07t5qZPHlyVF+yDnX11VdHZZ188snVTHK9StbuSynlBz/4QTWTPovX8rm3RLIWnB6jB+O92G6vx7W8ZiaZZK5YStYHt3zeIukv/s//+T9RWa95zWuqmWRslD6Xe8MNN1Qz73//+6OykucyknnuggULmtWXrqElZe2v46dWffD++e0AAAAAAAAAAAAAAIABw8sLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB0lJcXAAAAAAAAAAAAAACAjvLyAgAAAAAAAAAAAAAA0FFeXgAAAAAAAAAAAAAAADpqSMvCBg8eHOUGDaq/M5FkUkm70rYnudGjR0dlJbm1a9dWM1u2bInqW7NmTTVzxx13VDNjx46N6lu1alU185znPCcqa/ny5VGu5vbbb49yL3nJS6qZadOmPdvm7LN3795qJj1Ge3t7q5k9e/ZEZfX09ES5gSTZzsk2LiXbful+TfZZUtbIkSOj+pLje8eOHVFZu3btqmaSPn/y5MlRfRMnToxyNdu2bYtyw4cPr2buu+++qKytW7dWMyeeeGI1M2LEiKi+ZN+k/UCSGzKkPuxI+6f03OHZaXkdSMtq1R8k51MppaxcubKaWb9+fVTW9u3bq5nkmr979+6ovuRcP+aYY6qZ9Nqwc+fOaqbleCXZVulx1fL6nrQrOY7T+pK2n3LKKVFZ6XkxkCTbr2Vfl+7XoUOHVjPJWCtt+6RJk6qZdevWRWVt3Lixmkn6zYcffjiqb/Xq1dVMst2TcUjq9a9/fZQ77bTTqplkzp/u52Q7pNeYZJyY1Dd+/PiovmS9YvPmzVFZ5557bpTjl9dyjtAqU0rW5yfjmVKycyA5n5I+rJSsXcn4Iml3KaUcdthh1Uw6r5w5c2Y189rXvraaSa4vpZQyf/78aibpU0opZdOmTdXMo48+Ws3MnTs3qu+cc86pZtI58cGo5TpbIr0/kbSr5b2ObkvOpwceeCAqK8kl9S1ZsiSq784776xmnvvc50ZlJdK5QKLlPa1krWLq1KnVzPXXXx/Vl6ypXnzxxVFZ6b22gaZlf9ftfjHJJOsqLesrJdumydguuRdQSinDhg2LcjXf+973otzZZ59dzZx11llRWUm/+M///M/VzIIFC6L6xowZU80cccQRUVmf+MQnqplkDe0FL3hBVN9ll11WzSTjzYNVMt9I1s9S6bpQMi9J1nLS9dojjzyymvnxj38clZWs/Sbzm3RbJedmsj3TZ12Stcv03u6pp55azaTz60RyvWp5bW85R+n2PGygabnu1e2yWs5JEul86uSTT65mkufe0nlssr79rW99q5pJ+9ZRo0ZVM0uXLo3Kuuuuu6qZl770pdVMup7a8h5My/u6iZbzmJbjlwNFt58D7vazjOk+Tca3yRpNKdlzb8lzIOm69YoVK6qZpD9Mn9dbvHhxNZM+o5McD8nzRek5njxflD6f/MIXvrCaSY6/tJ/eH58DPnBXzQEAAAAAAAAAAAAAgAOClxcAAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo4a0LGzQoOxdiJ6enmpmyJCsaYMHD65mknalbZ80aVI1M2bMmKisESNGVDM7duyoZpJtUEopK1eubJJZu3ZtVN/OnTurmTVr1kRlbdy4sZqZPn16NbN169aovm9/+9vVzG/8xm9EZSXHe7IPe3t7o/r27t3bpL6DVct90VJSZ3L+rlq1Kqpv1KhR1czo0aOjsrZt2xblaiZOnBjlkrYn/VNq+/bt1UxyXpZSyo033ljNJH3Ki170oqi+PXv2NKkvldSXXv93795dzaRtP1j7xJb7Nikr7TuHDRtWzYwcObKaWbZsWVTfpk2bqpnNmzdHZSX9wa5du6KyWknGmy3PgfS4anX8pf1rS8m8Ienv0nMi2VbJeVNKKRMmTIhyA0my/Vr2h+n5lMzzEoccckiz+tK+LrkGJ5n0uE3mgkOHDq1m0nPuQx/6UDVzxhlnRGUl88/kmEmP0eQ7tiwryYwdOzaqLzlmTj311Kis9evXR7mBpOVxlEjX0NJcq3KSuUTLsUMyzlq9enVUVvIdDzvssGomXbNLypoyZUpU1hFHHFHNJOP39DqU9D3pemOyf5Lxe3Idaq3lOX2gSL5zy/sTaVmt7k8kc4j+kJxzDz74YFRWsi550003VTN33HFHVF+y3V/wghdEZSVricOHD69m0nWvpL70mpbUmYzN77333qi+z372s9XMpz71qaisd77znVFuoEn6lf649rS615r2r8kxnl4PkzqT8yCZt5SSnXfJGn46n7r22murmRe+8IVRWTNmzKhmpk2bFpWVSPZzeo8p2abJff4lS5ZE9SX3yNJj9NFHH41yA0kyR0ivm4mWZSX9Rbo2kfQr6fMNybMSyVzpoYceiupLju+kTcncupRS5s+fX82k/WbSrpb3NJPrUMt7K62eT0m1Wv85WHX7fm0p7dYSW47F0mdPkufxkvu16fwmWWtL1o7S+8PJ9TEdkyZ94qGHHlrNtFxrSecxyfZq2de1nHu0HHMcKFpeB1rOKRPJvk+P2w0bNlQz6TPFyfmbHN/pswELFy6sZo499thqJul/S8nuW6dj0hNOOKGaSdqejkmT4+++++6Lykpyr3/966uZZJ5bSrbe2HLNJmEUCQAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjhqTBwYMHVzM9PT1ZpUPq1Q4alL1XkdZZM378+Cg3e/bsambNmjVRWXPnzq1mVq1aVc1s2rQpqm/o0KHVzKxZs6qZ1atXR/Vt3bq1mpk/f35U1rp166qZ0047rZoZO3ZsVN9DDz1UzWzfvj0qa/To0dXM3r17o7ISybmT1tfq/DqQpH1PK+m+2Lx5czWzY8eOambx4sVRfUlZab+ZfMedO3dWMytWrIjqS87zZD/PmDEjqi+5Pibfr5RsW6XbPZG0vdt6e3ujXNL2tKyWffBAk14HknNq165dUVnJOZy0KxmHlFLKtm3bqpndu3dHZSXbITl202vRnj17qpkJEyY0qy/Z7ukxk5yfSVktr9vJ9ky13FbJ3Ckd46bX0oGk5THSsq9LzoGpU6c2qy+ZT6VlJfPBBQsWVDPJeLOUUsaNG1fNLFu2rJp51ateFdV3zjnnVDNr166Nymo11krHKi3HNK3mgqNGjYpy69evr2YOP/zwqKzkeB9oWs7dW84RWl0Puz1PLyVby5k+fXo188gjj0T1Jcdtsm+SsW0p2fg2WWcrJTs3N2zYUM0k6x5prmVZY8aMqWbS/qnlGJHOS/ueZFyXjOnTteZuS+YQ6bU3udfx6KOPVjMt51JbtmyJykrGysl1IRnzlJIdV+laxbBhw6qZRYsWVTP33HNPVF/Sb55wwglRWQer5F5ef4yPWtWZnsMt19CSXNJnpF75yldWM8n4KJlbl1LKiBEjqpnvf//7UVmnnHJKNZP01clcvpRShg8fXs2kY7uLLrqomknuqV9//fVRfStXrqxmkmtDKaX8/Oc/j3IDSbLv+6OvS67BRxxxRDWTjjGSZxKS+krJrsFJ35oc26VkfcGSJUuqmXRtO1lLTK6hpWTjo2SdreW9lZbrMa3uVaXMY59af/Rj3ZTei0/GWWlZyb2AtA9uJel7Dj300KisjRs3VjMXXHBBVNbJJ59czSR9a3rfIdkOLcfcLfuels/ZHYxarvF3+5qS1Jfe53rggQeqmfQZ32nTpkW5mmTMXUopS5curWaSMVv6bFwiff46uQdz1FFHVTPJuLWU7Pmb9Ji54YYbqpmbbrqpmnn9618f1Zf0+d0+Vwf2SAkAAAAAAAAAAAAAAOh3Xl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB0lJcXAAAAAAAAAAAAAACAjvLyAgAAAAAAAAAAAAAA0FFD+qPSnp6eJplSShkypP4VkrKGDx8e1bdz585qZsWKFVFZd999dzVz0003VTP3339/VN/s2bOrmXPPPbeamTBhQlRfsh127NgRlbV9+/ZqZvTo0dXMrl27ovqGDh1azYwcOTIqKz2WW5XT29tbzQwa5L2lp9Kyf0ps3bo1yiXH5LBhw6qZQw45JKpvz5491Ux6PiXH5KhRo6qZLVu2RPUtWrQoytWsW7euSTmllPLoo49GueTcfO5zn1vN7N69O6ov0fJ4T77f3r17o7KSdqV9XVrnQDN48OCulpX0K6WUMnXq1Gpm8+bN1czq1auj+jZt2lTNpH11ciy1PA+S8VEyXknG06217Fta1ddyrJXMGdI+Kqkvncukx/JAkmzndN8n52Z6DZ4xY0aUq1m/fn2US47JdG62Zs2aaibpn5JMKaWsWrWqmknGuK973eui+pLzJO03W/U9Lfun9BqTlJVI5iillDJ27NhqJjkWSill3LhxUe5gk479Wh6TrdYe0nJazhGS8zyZxyZj21KyvjXp888666yovjPPPLOamT59elRWcp4n6wfJuLyUUjZu3FjNpGOepF2HHnpoNTN58uSovkR6rrbqpweadLt0e/0vKSsdi7WU1Ll48eJqJpmjl5KNSY877rhqZunSpVF9hx9+eDWTrjcm/UrSbz788MNRfS2P0aTfvO6666qZdPyejOtOO+20qKyDVTJeabmul0rGR91eZ225ppVs0/Hjx0dlzZ07t5q5+uqrq5l0zp9shzlz5kRlPfjgg9VMsu46adKkqL5f/OIX1UxyLSolG5Nt2LChmkm3e3JtSPrEUrJjZqBJ1q1bzgVTSVnJOZeMe0rJ7kWOGDEiKivpo5I1ybRvTcaAyfdLzstSsvMpvXedrOEm9+ZTyTUmPY5brX10+7yhO/bX4yjJpedcMu9K1uOWLFkS1Zf050k/nY4jTzjhhGrmkksuicpKJOOsdJ0tyaVrH63mO+nzCYn0eO+PuVp/6/Z1J93Gyf5P7rGn95yOPvroauYnP/lJVFYy7kmey037ulbr2+k5l4wR0+vCzTffXM0kfd1hhx0W1ZdYvnx5lEvOnWQ7tLxX0O1xnSeYAQAAAAAAAAAAAACAjvLyAgAAAAAAAAAAAAAA0FFeXgAAAAAAAAAAAAAAADrKywsAAAAAAAAAAAAAAEBHeXkBAAAAAAAAAAAAAADoKC8vAAAAAAAAAAAAAAAAHeXlBQAAAAAAAAAAAAAAoKO8vAAAAAAAAAAAAAAAAHTUkDTY09NTzQwePDgqa9Cgdu9MtGxXYteuXdXM4sWLo7IefPDBauaBBx6oZu6+++6ovoULF1YzF110UTWTbINSStm+fXs1M3bs2Kis0aNHVzNDhtQP5/TYmzVrVjWTHlet2rVnz56ovsTevXujXMtz9UCR9Cnpdtm5c2c1s23btqisTZs2VTP3339/NbN169aovuTcTL5fKaVMnTq1mpk0aVI1k55zyXdcv359NZNs87Ssn//851FZ73znO6uZHTt2VDPpOT5q1Kgm9ZXS7lqb9nW9vb3Nymo5TjiQtOzjk/5gwoQJUVnDhw+vZlatWlXNbNiwIaovOdeTMU0ppezevbtrmVKyY/eaa66pZpLxXymljBs3rpppOV5JrslJX1BKKZs3b65m1q1bF5WV9PtJWelxdcghh1Qzydi1lFKe85znRLmDTXKslZIdb9OmTYvKGjp0aDWTHLfpcZSMOdesWROVlfSvSbu2bNkS1ZdshwsuuKCaSc+T5cuXVzPJHK+lltfstKzkGpPOZRLJuZP0v6WU8pOf/KSaeeUrXxmVdaBI+7FWZbWsr6V0DJVIvmMybk3mw6VkfWJy7Rg2bFhUX3JNS/uLpO0rVqyoZpYtWxbVl1yv0rWPxBlnnFHNJHPrVLrd03n/QNLt628quWYmmXTNPbn+jhw5MirrkUceqWaSex1Jf1hKNrdJxgRTpkyJ6ku2Q7q+ee6551Yzyb5J1yomT55czaRzgauuuqqaWb16dTWT3KMpJdvPI0aMiMo6WLUc/yd9Z8v7Rf0xd0kk3zHZVmmfkYyPxo8fX80k89NSSpk/f341c+yxx0ZlJX1nMr9O99+9995bzST3j9LcDTfcUM1Mnz49qi/ZDkuXLo3KSteTBpJ0/JBI5jfpOnIyp0qOtfSaP3PmzGomnSsdf/zx1Uyyfp+OJZM18FaZUrKxVjpeaSXt61quo7Saf7Rs08H4TEmq5Tpby+ehWh0jLc+BZN2rlHztq1V9SS7Znsk8qZRSLr300momHRs99thj1czcuXOrmWS+WErb9cYkl9SXPgeSXB/Tc/Vg7BO7fb8grS/Z/0nfumDBgqi+lStXVjPp/YJk7pk8I5ievxdeeGE1k4wR0+fskjWttN9M9mHy/HX6zMyiRYuqmY0bN0ZlJf1Fch1Kz4mW45J0flVz8PWYAAAAAAAAAAAAAABAV3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB0lJcXAAAAAAAAAAAAAACAjvLyAgAAAAAAAAAAAAAA0FFeXgAAAAAAAAAAAAAAADrKywsAAAAAAAAAAAAAAEBHDUmDgwbV33NIMqWU0tPTU80MHjw4KivN1ezduzfK9fb2VjMjRoyIypo8eXI1M3HixGom2Z6llHLEEUdUM9u3b69mVq9eHdW3YcOGambYsGFRWYcddlg1s23btmpm06ZNUX0nnnhiNTN8+PCorES6D7tdX3K8DzRpP5ZIjrc9e/ZEZSW5Xbt2VTMbN26M6kv6guQcL6WUJUuWVDMnnHBCNTNlypSovqRfSfrW9PhP+sTNmzdHZX3mM5+pZi699NJqZs6cOVF9kyZNqmZmzpwZlbVz584oV9NyLJEaO3Zss7IGmnQ77969u5pJjrdSStmxY0c1s379+mpm3bp1UX1Jv5iOE5PtsHXr1mpmyJBsiD506NBqJtkO//iP/xjV97u/+7vVTPL9Ssm2adL2hQsXRvWlx0Mi6e+S7bB8+fKovmuuuaaaSfZNKaWMHj06yg0kyXUlHY+NGTOmmknnCEmdW7ZsaZJpXdbatWubZJK+vJRs3Pazn/2smrn33nuj+mbNmlXNpH1dq7lFeh1Kjr+07Q8//HA1k4yD0+PqOc95TjWTjnG//OUvR7mBpOXcPSkrrS85dpPzJD0HknWhZLxWSra2l8w902tMco1O6ku/X7J+kG73pD9P+ovk2lFKNn5P1jRKKWXGjBnVzIUXXhiV1Uo6B2u5fnWgSLZNy7WCtKz0XKlJ73OMHDmySX2llDJ37txqJjl/Dz/88Ki+5NxM5m7HHntsVF/y/S666KKorFNOOaWaueqqq6qZUaNGRfWtWrWqmvnGN74RlfXYY49VM8cdd1yTckop5eijj45yiWTM0e17K93Q6r5nKW3v7bYsq9uSdiXrPcm6QCmlHHPMMdXMySefXM0sXrw4qi+ZC95xxx1RWZdcckk1k9xDXblyZVTfggULqpkzzjgjKivJfeUrX6lmDj300Ki+5B7ZnXfeGZV18cUXR7mBJLkmtuyf0utFMtZK7imlz0Ak9wLS+wXJ3OX73/9+NZOuHSXzz+R+T7pvknlsuq1aHTMt72mmZSXjhG5fs/fX6/+BYn/dfi3XG1uOb5Oyxo8fX81Mnz69RXNKKdlcN53HJvOpFStWRGUtXbq0mknGm+lcMBnfpnPiZP2v5bpycly1XBM/GKXX6JbrAEkuGc+kfVhyLyA5L9M6p06dWs0k90xKydb2Fi1aFJWVSOawaT+djDeTPiW9l5Ns9zVr1kRlJcd7t+dN3R6X7J+jIAAAAAAAAAAAAAAAYMDw8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB01JA02NPT08l2/NJ6e3urmaTte/fujepLckOHDo3KGjlyZDUzderUambmzJlRfevWratmbr311mpm/fr1UX1HHHFENXPkkUdGZY0YMaKa2bJlSzWza9euqL5DDz20mhk8eHBUVnLMJGWl9SXnxJ49e6Ky0vNiIBkypN4tpudAckyOHj06KmvHjh3VzLhx46KyWhk2bFiU27ZtWzVz//33VzPJNiillIkTJ1YzSb+5ffv2qL558+ZVM48++mhU1uTJk6uZpC9Pz/Gf/vSn1cyUKVOisoYPH17N7N69u5pJ+51Bg+rvX44ZMyYqa9OmTVFuoEmuK+l1MxnTpP1d0seuXbu2mtm4cWNUX9q3JJLttXPnzmomOb5TSV+d9AWllHLiiSdWM4cffnhU1sqVK6uZZD+nRo0aVc2kx3vSDy9btqyaSa+jxx13XDXTclw60CTXnuT4SHPp+CEZH7XKlFLK5s2bq5l0jLt69epqJumD03MuuZ4n2+HP//zPo/o+8YlPVDPpOZccf8n8Ix3nL1y4sJq58cYbo7KSeWUydp07d25UX3KMJv1hKaW8+tWvjnL88rq9Rphev5J+JS0rPc9blZOseyVjh3R8sWHDhmomWZMsJbsuJOOndF6W9Bdbt26Nyrr44ourmRkzZlQzSZ9ZSnbupGUlx3LLecX+INl+af+UbJuWZSWZVv3OM7Fq1apqZvr06dXMokWLovqS75iM/dJ5/KRJk6qZt73tbVFZSb+Z9j2J6667rppJ2lRKKbNnz65mknlMOtdJ7/kk9tf7kp3Wql95JrlWWq47tNwOSbuScVS6vpn0r8kaQ7pekdwTefjhh6OyPv3pT1czl156aTWT3rtO+rJ0/SCZ7yb7JhkjlpKtqaZj3Fe84hVRbiBJzrmW94taSo7JZBxSSim33357NXPSSSdFZSXrR8m1NT3nkvW4ZD+n9SW55F5VKdk9zWRulh57yXZP5wOtxkdpOUm7Dsb7Di2l9/WTfZasNZfS/efsku+YzvOS75iM2dJtlTz/l2yrdGyUtCudC65YsaJJWcnaXymlnHDCCdVMuu6V5lqV07Ifa9X2A0ly3KbXnZbrf63qS5+ZSvq65FmRUkq58847q5lkHvjAAw9E9SVtnzBhQjVzzjnnRPV95jOfqWauvvrqqKxk3J3MrdPrQiI9RpP7yOn4NrE/3i/Y/1oEAAAAAAAAAAAAAAAMKF5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI4akgYHDaq/59DT0/OsGvNM6yullMGDB1czSbuGDMk2RW9vb5RLjB49upqZMWNGNXPkkUdG9c2bN6+aWb16dTVzwgknRPVNnTq1mhk3blxU1po1a6qZdevWNWlTKaUccsgh1Ux6vKfHcs3evXublFNKdt6U0vacPlDs3r27mtm4cWNU1tChQ6uZnTt3RmVt3ry5mpk8eXI1M2rUqKi+bdu2VTO7du2Kyho5cmQ1s2nTpiaZUrJ+bP78+dVM0u5SSrn77rurmfTaceihh1YzyfGXtKmUUjZs2FDNpNfHpL9I+sO0z0z6xB/96EdRWS960Yui3ECTbMPt27dHZR111FHVTHoebN26tZrZsmVLNZP2Gcl3TPu7pO9MjBgxolmu5Rj+yiuvrGaOPfbYqKxZs2ZVM0mfmLZ95cqV1cyDDz4YlZUcM+edd141c/LJJ0f1Jfuw5ThxoEnOkzFjxkRl7dmzp5pJ+rBSsrFdcs1Pyikl6xOTMVQp2TmwY8eOamb8+PFRfcn+ScbBS5cujer73ve+V8382q/9WlRWsg+XLVtWzSRz+VJKeeCBB6qZ9Bozbdq0aua+++6rZiZNmhTV9/KXv7yaWb9+fVTWGWecEeXovFbrIS3XJtL5TbJukny/dM6frEUk0m2etGvhwoVRWY899lg1k6zZpeP35Fqbrn2cfvrp1UzLteCkrGS8UcrBuWbX7e+c1tfq/kTL77d8+fIol5ybp5xySjVz7bXXRvUl48hk/T4dE/yn//Sfqplhw4ZFZSVj0uRex4IFC6L6knF+Ml4rJRubJ9eF9BhN1wXojmS9IB0/tBrbtSqnlLb3upL+IG17MuZMzuFk/ayUUlasWFHNJPerSsnm10lZjz76aFTfS17ykmrmta99bVTWqlWrqpmLL764mpkwYUJU37/8y79UM9OnT4/KOvHEE6PcQJLOzRIt18CTa2Iyrk/neMna0eGHHx6VlYwzknal90OSuUsyN0vnQMn9l/RZkKTPT8ZQLZ9pSq9piaRd3a6Pp7a/zu+Tvi49jpK+NV1DGz58eDWTtCsdGyXP7CV9eVpf0tclz8+Vks35k7KSZxtLKeW4446rZtJnD5J+JTlG0/Or5fofTy7dxi3X0JL5cLfngelzssm6UDL2W7JkSVRfMqc87bTTqpnbb789qm/s2LHVTDquS9Yuk0y6npo8S5g8m1JK1ucnY+X0GO2PZ/ur5TQpBQAAAAAAAAAAAAAA4Cl4eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABARw1Jg4MHD65mBg3K3oVoWVYru3btinLbt2+vZvbu3RuVNWzYsCZlJduzlFLGjBlTzcyYMaOaOeaYY6L6Ro8eXc1s2bIlKivZP0l9733ve6P6krLSYzTZh0mm5TmRHqPdPg/3B0uXLq1m9uzZE5W1e/fuZ9ucfYYOHVrNJP3Ttm3bovqS7zhkSHYJadXnJ31mKaXs2LGjmpk/f341k26rnTt3VjPTp0+Pytq8eXM1s2DBgmomaVMppfzKr/xKNTNx4sSorOR437RpUzWzZMmSqL4f//jH1cz9998flXXCCSdEuYFm69at1cy4ceOispLjJDk3S8nalWTSa13Sd6bnVJKbPHlyNTNlypSovpEjR1YzSd+ZXq+SvnrEiBFRWcm1YcOGDdXMY489FtX3yCOPRLnEu971rmpm5syZ1Uw6/2g5Tmw5NjlQbNy4sZpJ+7pkfJRcy0vJxhnJXCk9jpKykm1VSnZMJmPXUaNGRfUl/UrSpsMPPzyq79/+7d+qmXS7J8fMgw8+WM2kx1WyTY8//viorLvuuquaSa6h73znO6P6km2aXtvT/TOQ9PT0dLWsA3mtIG17chwl49t0DJzMlZIxcDp/S8pavnx5VNbatWurmdWrV1czydivlGybnnrqqVFZs2fPjnI1Lc9Bnlq3+7qWkrni1KlTm9V3ww03RLlJkyZVM2PHjm2SKSX7jsOHD69mVq1aFdWXjh0Syfw7Wf9L57DJ9Spdu0zmAskcffz48VF9559/fpTjqSX7v+V4LF3n3x/HiWnbk/WQ9F5rIpkTJ+t/yTpiKVl/vm7duqisI444opq54IILqpnnPOc5UX3nnHNONZO2PVkHXblyZTWT3D8qpZT77ruvmnne854XlZVeSweS5PxN+5Skf0rP8WS+kRyTyRyolGzfJ+svqWQ7TJs2LSorGZMl47Fk/JdKnnUpJesvknWBdF7Rcv7R6r57f8xjD8a5c7f3fbe3cdq3Juvk6b3Y5Dsm93ySMU8pWV+wfv36JuWUkl1jkvFMWlZyvZo1a1ZUXzLnT58RbCU9J5JjOb3Hqq/bf8pKxputnuksJZsHps8bJm2fMGFCNZM8s1BKKTfddFOT+u69996ovle+8pXVzCte8YqorOT+djLGT58nSfqCdO0yKStpe8t5U7cduHcbAQAAAAAAAAAAAACAA4KXFwAAAAAAAAAAAAAAgI7y8gIAAAAAAAAAAAAAANBRXl4AAAAAAAAAAAAAAAA6yssLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjhqTBPXv2VDM9PT1RWYMG1d+ZSMtKcoMHD65mdu3aFdXXUrJNt2/fXs0MGZLtxnHjxlUzw4YNq2Z27twZ1bd3795qZvPmzVFZGzdurGZ+7dd+rZp5znOeE9WXSI7jVLKt0nOit7e3mknbnrRroNm2bVuzsnbv3l3NjB07Nipr1KhR1cz8+fOrmfvvvz+qb9OmTdXMihUrorKSPviII46oZkaPHh3Vt3jx4mpmx44d1Ux6/Cf7+bTTTovKevWrX13NjB8/vpo59NBDo/qS4+/uu++OyhozZkw1s3Tp0mrm5ptvjupL+vOzzjorKmv16tVRbqBJrgUzZ86MykquPVu3bo3KSnJJX53W13IMmIzJJkyYUM0kfX6aGzFiRDWT9ImpdHsuWrSomtmwYUM1k/SJpZTyyle+spo54YQTorKSOpPtkJw3pWTXo4NxzJb68Ic/XM288IUvjMo699xzq5lk3lJK1kcl53ja1yXnU3ocpfPBmmTuWUp2vUranoxJS8n6zR/84AdRWSNHjqxmkjHu4YcfHtW3ZcuWaiYZK5dSyq233lrNfOhDH6pm0v2c9JvmsU8tOb7Tc6DlWke3JXOzdA0tWa9K+uD0urBu3bpqJhk7JP1OKdn3W7VqVVRWq+2QrIGWkn3Hiy++uFlZ3XYgn4OdlvTvLbdfy/sTyX2ASZMmRfUla3sPP/xwVNab3/zmauaee+6pZtK2J2tHyT5M1hFLKeWRRx6JcolkHybjurTfScZ1rcblqcmTJ0e5dP/w7KT9Xcv7sYlu99Uttby3ltyPTfqMdO0o6V/T+ytJnbNnz65m0vuxyRg+vReVzHdXrlxZzSTXvlJKeeyxx6qZP/iDP4jK6o/nFPpbt8dtLfu6dG0lcdRRR1UzybpeKdmaVjLvSscYQ4cObVJW2tcl0rFWq2eMWq61tJx/JPWl273b59fBqOW4rttarsMmY4JSsvXm5BmIdHyR9HXJvkmfjUvKSp9tSOpcu3ZtNXPRRRdF9SX7JpnrltKuX2l5jWn5TOzBqOV2Sa+/yTgkGT8l/UAppQwfPryaSe8XJPeIkzlE0qZSsjHp9OnTq5lLL700qm/atGnVTNpvJvcxkmcg0+tQsjabzu+SOpPn/5J1y9Za9dN6TAAAAAAAAAAAAAAAoKO8vAAAAAAAAAAAAAAAAHSUlxcAAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo4akwcGDB1czPT09UVlJLqmvlFIGDaq/f5FkUtu2batmtm/f3qyspO2TJ0+O6uvt7a1mku2+Y8eOqL4tW7ZUM2vWrInKmjhxYjXz/Oc/v5oZOnRoVN/evXurmWR7lpJt0ySTtKmUUvbs2VPNpOfE7t27o9xAkhwjmzZtisoaMWJENZP2m0uWLKlm7rzzzmpm7ty5UX3Lli2rZtJjcvz48dXMhAkTqpm0b12xYkU1s2vXrmpmw4YNUX1vfOMbq5nf/M3fjMpKvmNy7Vi6dGlU38MPP9ykTaVkff6iRYuqmVe+8pVRfcl14cYbb4zKuuWWW6qZd7/73VFZB5LZs2dXM0OGZEPFjRs3VjNp35kc48lYZPPmzVF9SX+QXg9Hjx5dzYwaNaqaSa4fpWTXkKSvTrZBKdl5nhwLpZQybdq0auYVr3hFNXPqqadG9Q0bNqyaSa9rB/L4KB2/DiTr16+vZr7xjW9EZV1zzTXVzJw5c6KykrFPIh3Xr169uppJxpulZP15MqZOj8e0j6ppee6m/XQyV0/mguk2SK6hv/jFL6KyjjjiiGrmec97XjWTjiWT7ZDMdXlq6fZLx3+JZKyS9GPpOTBy5MhqJr3eJ3Umbd+5c2dUX7Ldk7l1sg1KyfqLtO3J3Hnr1q3N6rv00kurmec+97lRWa20XHtO14kORsnYIR1ftCwr6VeSsdFjjz0W1bd27dpq5pJLLonKmjRpUpP60r4nmQ8n58DRRx8d1Zesj1199dVRWS9+8YurmWRbpWsjSW748OFRWcnYNTne0/4p6c+TOfrBrNv3PVuW1bK+pH9Ny0rGWsmx23JembQ9PVdmzJhRzSTrI6WUMnbs2Gom2Z4tr8lp25N+Pxm7PvLII1F9ybj0sssui8pKrw8Hm/Ta03LNM7luJve6jjnmmKi+5J5CuuY+ZsyYaiY5n5IxTSmlrFu3rppJ+vK0b036zWR8W0q2RpIcf/3xfFSrOWPLtreucyBJzoF0za5lX9fq/mLappbnQNJvJnOldA006TeTcWRyj6aU7Bm69FmQZNyT9MEnnnhiVF+y3thyjNjNcp6JdP15IGl1H6CUrE9M+oFSSvn+979fzdxzzz3VzOte97qovqTvSc/f5P5EsuZ+1FFHRfWde+651UyyHpeu8Sd9YvpMcTJ2XbVqVTWTrrMl2z3dz+eff341k/TB6Xwyuda2XBNP+MsLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB0lJcXAAAAAAAAAAAAAACAjvLyAgAAAAAAAAAAAAAA0FFeXgAAAAAAAAAAAAAAADpqSBocNKj+nsPgwYOblZVk0jr37t1bzYwYMSKqb8+ePdXM7t27o7IS48ePr2Z27doVldXT01PNbNq0qZpJtkEppWzdurWa2blzZ1TW2972tmpm4sSJUVmJ9PhrJTlGu92mUkoZMiTuIgaMZF9MmjQpKivpn1asWBGVdcstt1Qzjz32WDWT9hdJbty4cVFZST+W9AVr1qyJ6kv6qCTzB3/wB1F9r3rVq6qZW2+9NSrrzjvvrGaSth922GFRfcm+OfLII6Oyli5dWs0873nPq2YOP/zwqL5//dd/rWZuuummqKzk+jgQJf1dci0vpZQdO3Y0K2vjxo3VzIYNG6qZdevWRfWl45rEhAkTqpnRo0dXM8OHD4/qS/rqVatWVTNbtmyJ6kv24fOf//yorDe84Q3VzOTJk6uZdP8lx3vaFyS5ZNyWtKm1g7G/S46RkSNHRmUlfU8yZksNGzasmknn4EmfmM5jx44dW820nEck2yGRfr+hQ4dWM+n3S/rX7du3VzPpNXTMmDHVzGtf+9qorAsvvDDK1bTsd1quEx2MWm6XltfMlsdIMs5Kxw7JOmFyzqXHbdLXJWPNtH9K1iLSvmflypXVTHIdSueeL33pS6uZdJ030R9jNp5ccj71R/+U5FqOjZJ1k7Tt27Zta5JJx9NJX5dsq2TdIM39j//xP6KyvvnNb1YzCxcurGbmzp0b1Zf0Y+l+Ts6d3t7eaiZdqzgY7ym01vJeUKs1jP6QHEvdvk6n9SXzz2RdL5mflpKNg5OxaynZnH/KlCnVTNpHLV++vJpZsGBBVNbixYurmUceeaSamTZtWlTfH//xH1cz6VrEwTiP3V+/c3LerV27tppJz4GkX1myZElUVnI9T/qe5PuV0q4PTufpyXUhvXedbKuW6xUt5x+t5kVpffvruXqgaDUHKqXtunWrstL1l+TeSjruSfqe5NmTtO9JxirJGn9yvzatL9mepZSyevXqaua0006rZk466aSovuR+yKhRo6Kykn66ZTlJLr3upc9kDSTJtmm5L9KykrH/z3/+82rmnnvuierbvHlzlEskx1HSj6XPJCZraElfkD67m/SbyTPMpWRtT7ZV2re27OuS56GTa1o6Xmu5htKqn94/V6QAAAAAAAAAAAAAAIABw8sLAAAAAAAAAAAAAABAR3l5AQAAAAAAAAAAAAAA6CgvLwAAAAAAAAAAAAAAAB3l5QUAAAAAAAAAAAAAAKCjvLwAAAAAAAAAAAAAAAB0lJcXAAAAAAAAAAAAAACAjvLyAgAAAAAAAAAAAAAA0FFDWhbW09PT9bL27t1bzQwdOrSaGTZsWFTftm3bqpldu3ZFZSVt3717dzWzZcuWqL4dO3ZUM8uXL69mRowYEdU3fvz4aub9739/VNbZZ59dzSTHzKBB2fs6yb5J9fb2VjNJu9I2DR48uEmbDlZ79uypZtLjaNOmTdXM4sWLo7JWrFhRzST9Rdo/jRw5sppJ+4Kkj3rkkUeqmWTflFLK1KlTq5kPfOAD1cyLX/ziqL4f//jH1Uyy/0opZfr06dVMsp9Hjx4d1Tdq1KhqZubMmVFZyT68//77q5mbb745qu+BBx6oZqZMmRKV1bLPP5Bs3bq1mknPuw0bNlQzaX+3ZMmSJmVt3rw5qi85p1JJv5hs02TMVkp2nUm257HHHhvV96Y3valZWYnk3OyPMU0y5mw5L0rHHYmDcQyYjn0SyTGZ7q/t27dXM/PmzatmhgzJpvTJNb/bx1ra/44dO7aaSfZzss1LyfZz2k8nbT/xxBOrmbPOOiuq79RTT61m0vFRsvaR7MP0uGo1bz5YtezrWq6ttNpn6Zg0OSZ37twZlZWsrSRjv2RNspSsv0jm6evXr4/qS3KrVq1qVlbSb770pS+N6psxY0Y103INLTmOW479Uv1RZ39r2T/1x32MVuUkfV3a9yT9azImSM6lUrLrVVJfsiZUSilz586tZtauXRuVde+991YzyfGX9OWltD3eEy3XxozZnr2W156W+6Pb+7bldkj6qSSTjrtbrTem/Xki6V9Lye6vJNePdFyarPMuXbo0KitZR0nuY3zxi1+M6kvunSTr5qXk6zs8uZbrtUlfkJwDydp9a8l5noxFkmc8Ssmer0nuQyWZUrK1vbTfTI6HVteONNdyrWV/nS/ur+3qpJtuuqmaSbdLcq1IryfJcTR8+PBqJh1fHHXUUdXMSSedFJX12GOPVTMt7/0mc6VJkyZVMxs3bozqW7ZsWTWTHjPJtSh5ruQ73/lOVF+y7trteWx6X7Tbz4ucfPLJXa1vf5Dui2TNPXn+oZRSHnrooWomGfek9yeS+ci4ceOispJxVjI/Xb16dVTfXXfdVc18+9vfrmaS+xyllDJx4sRqJrkPUErWjyV9T7qfk+vQ7/3e70VlJdsr6cv7Y42w1XMnVhEBAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI4akgYHDx7crNKWZQ0dOrSaOeqoo6qZxYsXR/UtW7asmtm8eXNU1rp166qZpF2rV6+O6tu5c2eUqxk9enSU+53f+Z1q5nnPe15UVk9PT5RrVc6gQd19r2fv3r3VTMs2JfWVUkpvb2+zOgeS9evXR7nk3Hz00UejstasWVPN7Nq1q5pJj6ORI0c2qa+UUvbs2VPNzJgxo5o5//zzo/re+c53VjPDhw+vZtK+deHChdXMddddF5V1zjnnVDNTpkypZlauXBnVN27cuGom7ae/973vVTM33nhjVFZiyJB4CFO1ffv2ZmUdSJLvvXbt2qisxx57rJpZtWpVVNaSJUua1Ldx48aovi1btlQzyXgztXXr1momHbOtWLGimjn11FOrmd/8zd+M6ps4cWI1k14b0rFIN7Uc97Qsqz/GgANJsi92794dlZXk0m08YsSIamb8+PHVzPz586P6kjlceqwl1+Ck30zGiKVk148JEyZUM0cffXRUXzI+StYYSinl3HPPrWZmz55dzaRrKNu2batmkutQKplfp3Nwc89n50c/+lE1M2zYsKisJJeWlfQFyb5PzpNSsr4uHd8mY8Rk3JP2dck1JjnHd+zYEdWXrEmmax9Ju5JxZLIuUEo2V0/ni0ku6YPTa2iSazn2S8YbPLX0GtZq3TqV1JfOYZN+LMkk/UApWV+X9NMPPvhgVF+ynpqsEZZSyrRp06qZpE9J5x7J9TG9xiT7MNkO6dzjrrvuqmbS9Ua6o+V1rKWkv0vnSsk8KPl+aZ+R9D/JeCxdY0jGrkmbSsnmu3Pnzq1m0vXNZJ03yZRSyr333lvNXHLJJdXMq1/96qi+ZB+2vI8x0LRcU+j2ODtpV3JelpL1K6NGjYrKGjt2bDWTzBGS+Vsp2T3uZF6Zzj3TsU8iuX6k47YDVbev6/1VZ3974IEHqpn9dSyW1Jc+T3H66ac/2+bsk96HrEnXNw855JBqJunHkvvfpWTz6/QeeDIOSZ5JXLRoUVRf0k+n9wGScXBSX8trRzquS8aIyfOUB5JkbJTu++RZtWTdoZTsuamkr0v7i+RZrgULFkRlzZw5s5pJtnva9lZaPk95//33R2Ul14WkL0/XUy+++OJq5oILLojK2rRpUzWTjFv749mUVs+dHHyjQwAAAAAAAAAAAAAAoKu8vAAAAAAAAAAAAAAAAHSUlxcAAAAAAAAAAAAAAICO8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAdNaRlYYMGZe9CpLnE4YcfXs3s3bu3mpk6dWpU37x586qZBx98MCpr/fr11czq1aurmW3btkX1JXp7e6uZl7/85VFZp5xySjUzePDgqKxWx0xPT0+TckrJtlVLaduTdrUsa6DZtGlTNZOcl6WU8uijj1Yz8+fPj8rasmVLNbN79+4mmVJKmTRpUjVzwgknRGWdeOKJ1cxZZ51VzYwfPz6q75prrqlmkr5848aNUX3J+XTYYYdFZV1//fXVzDnnnFPNnHnmmVF9EyZMqGbe/va3R2Ulx2hyXUiOvVJKue2226qZ9Pp4zDHHRLmBJunvli9fHpW1ePHiambDhg1RWStWrKhmVq5cWc2k5/CQIfXhcDoOSb5j0g8n52Yppfzqr/5qNXPJJZdUM8OHD4/q27VrVzWTjLtLybZpWtb+qOV8J9kO6diuZbsOFMn2S47tUvJxVKuyxowZU80MGzYsqm/nzp3VTNIfllLKjh07olzNmjVrotz73ve+aiYZr0yZMiWqL9mm6bZKjq1kvJLsv1Ky+Vs6B2/V96T904E8V98fzJ07t5pJrwHdvv7u2bOnmpk+fXqz+pJ5SynZODgZbyZrf6nRo0dXM9u3b4/KSsat6fUxySXt+uY3vxnVN2LEiGpm6NChUVlJn5iMlceNGxfVN2rUqGombfuRRx5ZzZx++ulRWQejpE9seW1qqWW7krKS4zud7yd9YtL/pmOjZC0xOS9LyY6ZJJO2PZkvpOteybU26Q9b9q08ey3HvC3Hfy3XHZLvmBzfpWT91LHHHlvNpGPJVvd20/qS+0zpfk76zl/84hfVzNatW6P6knXe22+/PSor6dP/x//4H9VM2le3XFc+kNdBf1kt+7Fuj9uSa2J6Dpx88snVTDo3S9bskvsv6b4ZO3ZsNTNy5MhqJl1nS/ZzOgdP6kyuMf0xZ0j6iwN5vjPQJNfV/XX8nBxrs2bNiso6/vjjq5mW95EXLVpUzaTbPenHkrHY2rVro/qS9cb03sq0adOqmWTOn45TkjW09BqTXPuS63Ha9mTcnW73JUuWRLmDTTouTq6/999/f1RWyzllK+n6fTInSfqxdG6TnHPpmC2RlJW2PdmmDz30UJM2lVLKZz7zmWomPa6Sfdhyrph8x7SfTtcJaw6+p1cAAAAAAAAAAAAAAICu8vICAAAAAAAAAAAAAADQUV5eAAAAAAAAAAAAAAAAOsrLCwAAAAAAAAAAAAAAQEd5eQEAAAAAAAAAAAAAAOgoLy8AAAAAAAAAAAAAAAAd5eUFAAAAAAAAAAAAAACgo7y8AAAAAAAAAAAAAAAAdJSXFwAAAAAAAAAAAAAAgI4a0t8NeCqjR4+OcmPGjKlmNm/eXM0MGpS9x/HiF7+4mlmxYkVU1rx586qZwYMHVzN79+6N6ksk2+Gcc86JykranmT2Vz09PVGut7e3mmm5Hfbs2dOsrIPRsmXLqpnFixdHZT322GPVzIYNG6KytmzZUs3MmDGjmrn88suj+k499dRqZs6cOVFZK1eurGY2btxYzUyaNCmqb8GCBdXM7t27q5nly5dH9V144YXVzNatW6OykuvH9773vWrmhBNOiOqbO3duNZMe76NGjapmzj333Gpm4sSJUX333XdfNXPyySdHZU2ZMiXKDTS7du2qZtavXx+VlfSd6Tm1aNGiaibpM4YNGxbVl4yj0nN4yJD60Priiy+uZl72spdF9R122GHVTDIOSfrEVDqmTrZ70vaW0jF10q5knNhyW6XSOgeSnTt3VjNJf1hK232RlJX0KankuO32sZZeY4477rhq5thjj61m1q5dG9WX9InJcVVKtt2TbdVy7pnu56TOVt8vLWvEiBFRWddee201k85lDhTptmmlZX+RmDBhQpRrOb5I5uBr1qypZv6/9u4eR5EYCANobYAQEQESEmQgEXBSjkkECUgEBEDEXGBG/gKb1c6+F5faDU3b5Z8Sz+czai95hsnnu16vUXuv16sZk/Z1yX0luXk6LiTSMXSz2TRjkv6i53NO+3y+1/P76zkf6XlfPfPI8/ncjLnf782YyWQStZfEJetL6TpOktel6/K98qzpdBq1l0ivlewX9MzF1ut1FMfPkt9ummf37H+SNj+dJz4ejyhusVg0Y5L95uPxGLWX7Psk32e6f5Rca7VaRddK3vVkDyYZP6qqLpdLMyYZr6qqDodDM2a73TZjkjy/6t/e4+ZnvZ5rul+f7H2mc6XkTEwi7XuS8SrpU9IcI1nDTfbmq7J8OZ3n9dJzzP70vPJ/3Hfoqef5nnQemzyzJM9KzyQkeVaa191ut2bM6XRqxsxms6i9pC9I+un08yV9cPqOz+fzZkzPtY+ee9LJtZJxLznDUJXlm8lvryrfc/xNkueVrh0l50CS87ZV2Zp0z/E+6QvSMTN5Vz79zvW6p1R6Rif5TpP3cr/fR+0tl8tmTM+xvdeYXZXNv9P5UNJv7na7ZowsEgAAAAAAAAAAAAAAGErxAgAAAAAAAAAAAAAAMJTiBQAAAAAAAAAAAAAAYCjFCwAAAAAAAAAAAAAAwFCKFwAAAAAAAAAAAAAAgKEULwAAAAAAAAAAAAAAAEMpXgAAAAAAAAAAAAAAAIZSvAAAAAAAAAAAAAAAAAz15/1+v//2TQAAAAAAAAAAAAAAAL+Xf14AAAAAAAAAAAAAAACGUrwAAAAAAAAAAAAAAAAMpXgBAAAAAAAAAAAAAAAYSvECAAAAAAAAAAAAAAAwlOIFAAAAAAAAAAAAAABgKMULAAAAAAAAAAAAAADAUIoXAAAAAAAAAAAAAACAoRQvAAAAAAAAAAAAAAAAQyleAAAAAAAAAAAAAAAAhvoCozZzY+Oe32YAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(40,40))\n",
        "\n",
        "num_images = 10\n",
        "for i in range(num_images):\n",
        "    row = x_train[i]\n",
        "    label = y_train[i]\n",
        "\n",
        "    image = row.reshape(28,28)\n",
        "    plt.subplot(1, num_images, i+1)\n",
        "    plt.title(label, fontdict={'fontsize': 30})\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Data for Training"
      ],
      "metadata": {
        "id": "tK22VzRDM7bV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deep learning, it is common that data needs to be transformed to be in the ideal state for training. For this particular image classification problem, there are 3 tasks we should perform with the data in preparation for training:\n",
        "1. Flatten the image data, to simplify the image input into the model\n",
        "2. Normalize the image data, to make the image input values easier to work with for the model\n",
        "3. Categorize the labels, to make the label values easier to work with for the model"
      ],
      "metadata": {
        "id": "_T8Su90iM7pK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing the Image Data"
      ],
      "metadata": {
        "id": "vNlsswaSNtQn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y33lIGXvYPUt"
      },
      "source": [
        "Deep learning models are better at dealing with floating point numbers between 0 and 1 (more on this topic later). Converting integer values to floating point values between 0 and 1 is called [normalization](https://developers.google.com/machine-learning/glossary#normalization), and a simple approach we will take here to normalize the data will be to divide all the pixel values (which if you recall are between 0 and 255) by 255:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {
        "id": "v2ce2nBxYPU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ac806d-9d1e-46a5-a143-236587b9074e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 489
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 490,
      "metadata": {
        "id": "Rh8272ObYPU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3546f5bf-0cfa-406a-e2a6-7c010911c635"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 490
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 491,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "KQLwvUoPYPU0"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-9gtN98OPKY",
        "outputId": "c21eeef4-92b4-45d8-f75b-447be07dd408"
      },
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 492
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3JFQNmOPNt",
        "outputId": "06739403-0fc8-4157-88c0-6dd27eb16859"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MFy8iQLYPU0"
      },
      "source": [
        "## Categorize the Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd70-f6kYPU1"
      },
      "source": [
        "We are going to categorically encode the labels. We can use the [keras.utils.to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) method to accomplish this by passing it the values to encode, and, the number of categories to encode it into. Categorical encoding is a vital preprocessing step in machine learning to convert categorical variables into numerical format. This enables machine learning algorithms, which require numerical input, to effectively process and make predictions on diverse datasets. Encoding techniques like one-hot encoding and ordinal encoding preserve the underlying information of the categories and maintain compatibility with various algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 494,
      "metadata": {
        "id": "LLpQZdBFYPU1"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "num_classes = 26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 495,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "fn93ZRXZYPU1"
      },
      "outputs": [],
      "source": [
        "if not y_train.shape[-1] == 26:  # Avoid running multiple times\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_valid = keras.utils.to_categorical(y_valid, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjp3Oyugzkq2"
      },
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following table shows for each image `X`, the encoded `Y` based on 26 classes hence 26 elements with one-hot encoding. One-hot encoding is a popular technique where each category is represented in binary (0 or 1). Each label vector has the same length as the total number of categories, and all elements are zero except for the index that corresponds to the category, which is set to one. One-hot encoding ensures that each category is uniquely represented, and it is particularly useful when there is no ordinal relationship among the categories."
      ],
      "metadata": {
        "id": "9aWVSRATWxNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "df= pd.DataFrame(y_train[0]).astype(int)\n",
        "alphabet = list(string.ascii_uppercase)\n",
        "df['Letter'] = alphabet[:len(df)]\n",
        "df=df.rename(columns={0: 'One-hot Code'})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "kZG1DyEErpEZ",
        "outputId": "b50cbf8d-cc59-4102-b276-f4c979fb10d5"
      },
      "execution_count": 496,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    One-hot Code Letter\n",
              "0              0      A\n",
              "1              0      B\n",
              "2              0      C\n",
              "3              1      D\n",
              "4              0      E\n",
              "5              0      F\n",
              "6              0      G\n",
              "7              0      H\n",
              "8              0      I\n",
              "9              0      J\n",
              "10             0      K\n",
              "11             0      L\n",
              "12             0      M\n",
              "13             0      N\n",
              "14             0      O\n",
              "15             0      P\n",
              "16             0      Q\n",
              "17             0      R\n",
              "18             0      S\n",
              "19             0      T\n",
              "20             0      U\n",
              "21             0      V\n",
              "22             0      W\n",
              "23             0      X\n",
              "24             0      Y\n",
              "25             0      Z"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-02ebcacd-bfa6-4190-970d-a8f4d4c6be66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>One-hot Code</th>\n",
              "      <th>Letter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02ebcacd-bfa6-4190-970d-a8f4d4c6be66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b5d10f60-bb25-45e6-af91-8348ad0f2faf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5d10f60-bb25-45e6-af91-8348ad0f2faf')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b5d10f60-bb25-45e6-af91-8348ad0f2faf button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02ebcacd-bfa6-4190-970d-a8f4d4c6be66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02ebcacd-bfa6-4190-970d-a8f4d4c6be66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 496
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can show many data points at once and this will be a matrix instead of one list. Each row represents on image and you can check the shape."
      ],
      "metadata": {
        "id": "u12vzQBoZcOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "id": "CHDN5pFiy0a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b1cff0-5d97-4c81-e43b-974062b7b3f0"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 497
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfwreXBIq5Et",
        "outputId": "1de4f3dc-f05d-4216-9980-3223669dafb5"
      },
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 498
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzVeCQi75v4d",
        "outputId": "0c9638b8-b716-4002-c9b0-5b0fb3bd3728"
      },
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 499
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dqSHO4SYPU1"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyLRZtkpYPU1"
      },
      "source": [
        "The data is all prepared, we have normalized images for training and validation, as well as categorically encoded labels for training and validation.\n",
        "\n",
        "For this exercise we are going to build a sequential model. Just like last time, build a model that:\n",
        "* Has a dense input layer. This layer should contain 512 neurons, use the `relu` activation function, and expect input images with a shape of `(784,)`\n",
        "* Has a second dense layer with 512 neurons which uses the `relu` activation function\n",
        "* Has a dense output layer with neurons equal to the number of classes, using the `softmax` activation function\n",
        "\n",
        "Do your work in the cell below, creating a `model` variable to store the model. We've imported the Keras [Sequental](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class and [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class to get you started. Reveal the solution below for a hint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 500,
      "metadata": {
        "id": "5KsqfViOYPU2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 501,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "RRzhKKWLYPU2"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units = 512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(units = 512, activation='relu'))\n",
        "model.add(Dense(units = num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3N6WJM1YPU2"
      },
      "source": [
        "## Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m36xB2DwYPU2"
      },
      "source": [
        "Run the cell below to summarize the model you just created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 502,
      "metadata": {
        "id": "ihdBN7HEYPU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7addb5b4-14ec-427f-8b90-9695beda9955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 26)                13338     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 677,914\n",
            "Trainable params: 677,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtQBlcw_YPU3"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urgrxBcGYPU3"
      },
      "source": [
        "We'll [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) our model with the same options as before, using [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) to reflect the fact that we want to fit into one of many categories, and measuring the accuracy of our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 503,
      "metadata": {
        "id": "l01dCezQYPU3"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzL7iqmrYPU3"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 504,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "p06Sd-vAYPU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c59c16-703f-44af-fc7c-789a703a58f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 1.9410 - accuracy: 0.3831 - val_loss: 1.7175 - val_accuracy: 0.4370\n",
            "Epoch 2/10\n",
            "858/858 [==============================] - 10s 12ms/step - loss: 0.9629 - accuracy: 0.6754 - val_loss: 1.3843 - val_accuracy: 0.5627\n",
            "Epoch 3/10\n",
            "858/858 [==============================] - 8s 10ms/step - loss: 0.5844 - accuracy: 0.8042 - val_loss: 0.8171 - val_accuracy: 0.7616\n",
            "Epoch 4/10\n",
            "858/858 [==============================] - 10s 11ms/step - loss: 0.3909 - accuracy: 0.8748 - val_loss: 0.7232 - val_accuracy: 0.8076\n",
            "Epoch 5/10\n",
            "858/858 [==============================] - 10s 11ms/step - loss: 0.2951 - accuracy: 0.9112 - val_loss: 1.0748 - val_accuracy: 0.7137\n",
            "Epoch 6/10\n",
            "858/858 [==============================] - 9s 11ms/step - loss: 0.2363 - accuracy: 0.9344 - val_loss: 1.1703 - val_accuracy: 0.7423\n",
            "Epoch 7/10\n",
            "858/858 [==============================] - 9s 10ms/step - loss: 0.2129 - accuracy: 0.9447 - val_loss: 0.7164 - val_accuracy: 0.8484\n",
            "Epoch 8/10\n",
            "858/858 [==============================] - 9s 11ms/step - loss: 0.1924 - accuracy: 0.9539 - val_loss: 1.6777 - val_accuracy: 0.6966\n",
            "Epoch 9/10\n",
            "858/858 [==============================] - 9s 11ms/step - loss: 0.1991 - accuracy: 0.9590 - val_loss: 0.7833 - val_accuracy: 0.8313\n",
            "Epoch 10/10\n",
            "858/858 [==============================] - 8s 10ms/step - loss: 0.1611 - accuracy: 0.9640 - val_loss: 2.2956 - val_accuracy: 0.6718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c53f8658be0>"
            ]
          },
          "metadata": {},
          "execution_count": 504
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=10, verbose=1, validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gBpCdCDYPU4"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TQj9DCaYPU5"
      },
      "source": [
        "In this section you built your own neural network to perform image classification that is quite accurate. Congrats!\n",
        "\n",
        "At this point we should be getting somewhat familiar with the process of loading data (incuding labels), preparing it, creating a model, and then training the model with prepared data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuUSeLhgYPU5"
      },
      "source": [
        "## Next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XTOhqEGYPU5"
      },
      "source": [
        "Now that you have built some very basic, somewhat effective models, we will begin to learn about more sophisticated models, including *Convolutional Neural Networks*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2FCYUxUYPU5"
      },
      "source": [
        "# Section 2: Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_2Zj0DHYPU6"
      },
      "source": [
        "In the previous section, we built and trained a simple model to classify ASL images. The model was able to learn how to correctly classify the training dataset with very high accuracy, but, it did not perform nearly as well on validation dataset. This behavior of not generalizing well to non-training data is called [overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html), and in this section, we will introduce a popular kind of model called a [convolutional neural network](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) that is especially good for reading images and classifying them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RJWsagnYPU6"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpnjtDpTYPU6"
      },
      "source": [
        "* Prep data specifically for a CNN\n",
        "* Create a more sophisticated CNN model, understanding a greater variety of model layers\n",
        "* Train a CNN model and observe its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPYhMmPuYPU6"
      },
      "source": [
        "## Loading and Preparing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuKg5ke5YPU6"
      },
      "source": [
        "The below cell contains the data preprocessing techniques we learned in the previous labs. Review it and execute it before moving on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 505,
      "metadata": {
        "id": "0AZZPUo6YPU6"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "\n",
        "# Load in our data from CSV files\n",
        "train_df = pd.read_csv(\"sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"sign_mnist_test.csv\")\n",
        "\n",
        "# Separate out our target values\n",
        "y_train = train_df['label']\n",
        "y_valid = valid_df['label']\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "\n",
        "# Separate out our image vectors\n",
        "x_train = train_df.values\n",
        "x_valid = valid_df.values\n",
        "\n",
        "# Turn our scalar targets into binary categories\n",
        "num_classes = 26\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "\n",
        "# Normalize our image data\n",
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E1u2ASoYPU6"
      },
      "source": [
        "## Reshaping Images for a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3WO9LUAYPU6"
      },
      "source": [
        "In the last exercise, the individual pictures in our dataset are in the format of long lists of 784 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 506,
      "metadata": {
        "id": "H2RkFdaWYPU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc82ece-f531-4d33-96c7-c7e3fa5fddac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27455, 784), (7172, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 506
        }
      ],
      "source": [
        "x_train.shape, x_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LeOkf2vYPU6"
      },
      "source": [
        "In this format, we don't have all the information about which pixels are near each other. Because of this, we can't apply convolutions that will detect features. Let's reshape our dataset so that they are in a 28x28 pixel format. This will allow our convolutions to associate groups of pixels and detect important features.\n",
        "\n",
        "Note that for the first convolutional layer of our model, we need to have not only the height and width of the image, but also the number of [color channels](https://www.photoshopessentials.com/essentials/rgb/). Our images are grayscale, so we'll just have 1 channel.\n",
        "\n",
        "That means that we need to convert the current shape `(27455, 784)` to `(27455, 28, 28, 1)`. As a convenience, we can pass the [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape) method a `-1` for any dimension we wish to remain the same, therefore:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 507,
      "metadata": {
        "id": "SNbti7AIYPU7"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_valid = x_valid.reshape(-1,28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 508,
      "metadata": {
        "id": "8P6uJzsIYPU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4502863a-535d-49c3-cf01-32a59383cc57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 508
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 509,
      "metadata": {
        "id": "ghcxHa5CYPU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a35737-3d8f-4fcf-a9bf-2585e6a1b953"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 509
        }
      ],
      "source": [
        "x_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 510,
      "metadata": {
        "id": "8ndZeppSYPU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666cc11f-b193-4f63-efa0-fe43c5185d61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27455, 28, 28, 1), (7172, 28, 28, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 510
        }
      ],
      "source": [
        "x_train.shape, x_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5GgfcVrYPU7"
      },
      "source": [
        "## Creating a Convolutional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewNJwDg-YPU7"
      },
      "source": [
        "These days, many data scientists start their projects by borrowing model properties from a similar project. Assuming the problem is not totally unique, there's a great chance that people have created models that will perform well which are posted in online repositories like [TensorFlow Hub](https://www.tensorflow.org/hub) and the [PyTorch Hub](https://pytorch.org/hub/). However, today we'll provide a model that is simpler to study and understand but still will work well for this problem.\n",
        "\n",
        "We covered many of the different kinds of layers in the lecture, and we will go over them all here with links to their documentation. When in doubt, read the official documentation (or ask [stackoverflow](https://stackoverflow.com/))."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmenpvS2uCbP"
      },
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 511,
      "metadata": {
        "id": "6oH1d8WvYPU8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    MaxPool2D,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\",\n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=num_classes, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPmoceuYPU8"
      },
      "source": [
        "### [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVBQ296HYPU8"
      },
      "source": [
        "These are our 2D convolutional layers. Small kernels will go over the input image and detect features that are important for classification. Earlier convolutions in the model will detect simple features such as lines. Later convolutions will detect more complex features. Let's look at our first Conv2D layer:\n",
        "```Python\n",
        "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same'...)\n",
        "```\n",
        "75 refers to the number of filters that will be learned. (3,3) refers to the size of those filters. Strides refer to the step size that the filter will take as it passes over the image. Padding refers to whether the output image that's created from the filter will match the size of the input image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l2y1LjSYPU8"
      },
      "source": [
        "### [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdW0hxbrYPU8"
      },
      "source": [
        "Like normalizing our inputs, batch normalization scales the values in the hidden layers to improve training. [Read more about it in detail here](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHQfnWqgYPU8"
      },
      "source": [
        "### [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJN-zkVBYPU9"
      },
      "source": [
        "\n",
        "Max pooling takes an image and essentially shrinks it to a lower resolution. It does this to help the model be robust to translation (objects moving side to side), and also makes our model faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Tmj-jiYPU9"
      },
      "source": [
        "### [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld3fWaXaYPU9"
      },
      "source": [
        "Dropout is a technique for preventing overfitting. Dropout randomly selects a subset of neurons and turns them off, so that they do not participate in forward or backward propagation in that particular pass. This helps to make sure that the network is robust and redundant, and does not rely on any one area to come up with answers.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqI4NF9KYPU9"
      },
      "source": [
        "### [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF2q9eboYPU9"
      },
      "source": [
        "Flatten takes the output of one layer which is multidimensional, and flattens it into a one-dimensional array. The output is called a feature vector and will be connected to the final classification layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YN7nN3XYPU9"
      },
      "source": [
        "### [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUtotLR8YPU9"
      },
      "source": [
        "We have seen dense layers before in our earlier models. Our first dense layer (512 units) takes the feature vector as input and learns which features will contribute to a particular classification. The second dense layer (24 units) is the final classification layer that outputs our prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3RG9EziYPU9"
      },
      "source": [
        "## Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ_p4l8TYPU9"
      },
      "source": [
        "This may feel like a lot of information, but don't worry. It's not critical that to understand everything right now in order to effectively train convolutional models. Most importantly we know that they can help with extracting useful information from images, and can be used in classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfgVKSN4YPU9"
      },
      "source": [
        "Here, we summarize the model we just created. Notice how it has fewer trainable parameters than the model in the previous notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 512,
      "metadata": {
        "id": "5OhMPhMMYPU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454f92f1-33b1-4cfe-84d8-76e52c2158c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 75)        750       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 28, 28, 75)       300       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 75)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 50)        33800     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14, 14, 50)        0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 14, 14, 50)       200       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 50)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 25)          11275     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 7, 7, 25)         100       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 4, 4, 25)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 512)               205312    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 26)                13338     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 265,075\n",
            "Trainable params: 264,775\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdfgxZKjYPU-"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJIUbrkRYPU-"
      },
      "source": [
        "We'll compile the model just like before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 513,
      "metadata": {
        "id": "ti-CzVamYPU-"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqzSsq_3YPU-"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKnW1MhpYPU-"
      },
      "source": [
        "Despite the very different model architecture, the training looks exactly the same. Run the cell below to train for some epochs and let's see if the accuracy improves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 514,
      "metadata": {
        "id": "QjGOzyu_YPU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718b872e-4f1d-40b3-c27c-8d453add87ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "858/858 [==============================] - 123s 142ms/step - loss: 0.3093 - accuracy: 0.9044 - val_loss: 0.2896 - val_accuracy: 0.9060\n",
            "Epoch 2/5\n",
            "858/858 [==============================] - 118s 138ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.2311 - val_accuracy: 0.9282\n",
            "Epoch 3/5\n",
            "858/858 [==============================] - 117s 136ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.2269 - val_accuracy: 0.9377\n",
            "Epoch 4/5\n",
            "858/858 [==============================] - 121s 141ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0768 - val_accuracy: 0.9714\n",
            "Epoch 5/5\n",
            "858/858 [==============================] - 121s 141ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1875 - val_accuracy: 0.9540\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c5416666bc0>"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6agD4STjYPU-"
      },
      "source": [
        "## Discussion of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeIV0h6mYPU-"
      },
      "source": [
        "It looks like this model is significantly improved! The training accuracy is very high, and the validation accuracy has improved as well. This is a great result, as all we had to do was swap in a new model.\n",
        "\n",
        "You may have noticed the validation accuracy jumping around. This is an indication that our model is still not generalizing perfectly. Fortunately, there's more that we can do. Let's talk about it in the next lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpuoslI5YPU-"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgdrYVG0YPU-"
      },
      "source": [
        "In this section, we utilized several new kinds of layers to implement a CNN, which performed better than the more simple model used in the last section. Hopefully the overall process of creating and training a model with prepared data is starting to become even more familiar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59P3iAMIYPU_"
      },
      "source": [
        "## Next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvBIPvoZYPU_"
      },
      "source": [
        "In the last several sections you have focused on the creation and training of models. In order to further improve performance, you will now turn your attention to *data augmentation*, a collection of techniques that will allow your models to train on more and better data than what you might have originally at your disposal."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}